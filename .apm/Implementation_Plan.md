# apm-auto Automation Framework – Implementation Plan

**Memory Strategy:** Dynamic-MD (directory structure with Markdown logs)
**Last Modification:** Initial plan created by Setup Agent
**Project Overview:** apm-auto is an automation orchestration system extending the existing Agentic Project Management (APM) framework to eliminate manual agent coordination. The system automates the full agent lifecycle—spawning Manager and Implementation agents via Claude Code CLI, managing inter-agent communication through file-based protocols, coordinating parallel execution using git worktrees, and enforcing constitutional quality gates from spec-kit patterns. Core features include SQLite state management with deep beads issue tracking integration for dependency-driven decisions, automated session persistence with error recovery, and eventual TUI-based monitoring. The MVP delivers walk-away automation for scope-defined work with intelligent checkpointing, while v2/v3 add git worktree parallelization, terminal user interface, and configurable autonomy levels (Cautious/Automated/YOLO).

---

## Phase 1: Foundation & State Management

### Task 1.1 – Database Schema Design and SQLite Initialization │ Agent_Orchestration_Foundation

- **Objective:** Establish the foundational SQLite database schema and connection layer for apm-auto state persistence, following proven codeframe architectural patterns to support agent tracking, task management, session state, and comprehensive audit logging.
- **Output:** Complete database schema definition with TypeScript-typed connection manager, initialization functions, and passing test suite validating schema integrity and connection reliability.
- **Guidance:** Depends on Task 1.3 Output. Design schema based on codeframe database patterns reviewed during Context Synthesis (projects, agents, tasks, state transitions, execution logs tables). Use TypeScript strict mode for type safety. Implement connection pooling for concurrent access. Follow TDD methodology—write tests first, then implement schema creation logic. Ensure foreign key constraints are properly defined for referential integrity. Migration-ready schema design to support future evolution via Task 1.4 infrastructure.

1. **Schema Design:** Analyze codeframe database structure (`projects`, `agents`, `tasks`, `state`, `logs` tables) and adapt for apm-auto requirements including agent types (Manager, Implementation, Ad-Hoc), state transitions (spawn/active/waiting/idle/terminated), task dependencies, session checkpoints, and worktree mappings. Define comprehensive schema with proper indexing for query performance, foreign key relationships for data integrity, and timestamp tracking for audit trails. Document schema design decisions and table relationships.

2. **Connection Manager Implementation:** Create TypeScript connection manager class with strict typing, implementing connection pooling to support concurrent agent operations, transaction support for atomic state updates, and graceful error handling with connection retry logic. Export strongly-typed database interface matching schema structure. Use SQLite PRAGMA settings for optimal performance (foreign_keys=ON, journal_mode=WAL for concurrent reads).

3. **Initialization Functions:** Implement database initialization logic with idempotent schema creation (CREATE TABLE IF NOT EXISTS), automatic schema validation on startup, and comprehensive error reporting for schema creation failures. Create database setup utilities for test environments and production initialization. Support both file-based and in-memory database modes for testing flexibility.

4. **Test Suite:** Write comprehensive test suite following TDD principles covering schema creation validation (all tables/indexes exist), connection lifecycle management (open/close/pool), transaction rollback scenarios, foreign key constraint enforcement, and concurrent access patterns. Achieve 80% minimum coverage. Ensure 100% pass rate with no skipped tests. Tests must validate schema matches TypeScript type definitions from Task 1.3.

### Task 1.2 – Beads Issue Tracking Integration │ Agent_Orchestration_Foundation

- **Objective:** Integrate the beads CLI issue tracker to enable dependency-driven state machine decisions, allowing apm-auto to query ready work, detect blockers, and track task dependencies through beads' native graph-based issue management.
- **Output:** TypeScript wrapper module for beads CLI commands with strongly-typed query functions, state machine integration logic that consumes beads dependency data, and comprehensive test suite validating beads command execution and state integration.
- **Guidance:** Depends on Task 1.1 Output. Beads CLI (`bd`) is already installed and available per Context Synthesis. Implement TypeScript wrapper using child_process for CLI execution with proper error handling and JSON output parsing. Map beads issue states to apm-auto agent task states. Use beads dependency graph (`bd dep tree`) to inform state machine task ordering and readiness detection. Follow TDD methodology. Ensure graceful degradation if beads commands fail (log warning, continue with limited functionality).

1. **CLI Wrapper Implementation:** Create TypeScript module wrapping beads CLI commands (`bd ready --json`, `bd list --json`, `bd show <id> --json`, `bd dep tree <id> --json`) using Node.js child_process with async/await patterns. Implement proper command execution with timeout handling, stderr capture for error reporting, and JSON response parsing with schema validation. Handle beads CLI errors gracefully with descriptive error messages. Export strongly-typed interfaces matching beads JSON output structure (Issue, Dependency, Status enums).

2. **State Query Functions:** Implement high-level query functions (`getReadyTasks()`, `getBlockers()`, `getDependencies(issueId)`) that abstract beads CLI details and return TypeScript-typed results. `getReadyTasks()` queries beads for issues with no open blockers. `getBlockers()` identifies tasks preventing progress. `getDependencies(id)` retrieves full dependency graph for task ordering. Cache query results with TTL to reduce CLI overhead. Implement query result mapping to apm-auto internal task representation.

3. **State Machine Integration:** Integrate beads query functions into state machine decision-making logic, using beads dependency data to determine task execution order, identify which tasks can run in parallel, and detect blocking conditions requiring user intervention. Map beads issue status (pending/in_progress/completed/failed) to apm-auto agent task states. Update state database with beads-derived task readiness and dependency information. Implement periodic beads sync to keep state machine current.

4. **Integration Testing:** Write comprehensive tests covering beads CLI execution (mock child_process for unit tests), JSON parsing and schema validation, query function return values matching beads data structures, state machine integration consuming beads dependency data correctly, and error handling for beads CLI failures. Test graceful degradation when beads unavailable. Achieve 80% coverage minimum with 100% pass rate.

### Task 1.3 – State Machine Models and TypeScript Types │ Agent_Orchestration_Foundation

- **Objective:** Define comprehensive TypeScript type system for apm-auto state machine including agent states, task states, session states, state transitions, and all data models to ensure type safety throughout the codebase and guide database schema design.
- **Output:** Complete TypeScript type definition module with interfaces, enums, type guards, and schema validation utilities exported for use across all apm-auto modules, serving as the type foundation for database schema (Task 1.1) and state management logic.
- **Guidance:** Types defined here inform database schema column definitions in Task 1.1. Use TypeScript strict mode with no implicit any. Define discriminated unions for state variants. Include JSDoc comments for all exported types. Export schema validation functions using a library like zod or joi for runtime type checking at API boundaries. Organize types logically (agent types, task types, session types, shared types). Follow existing apm type patterns for consistency.

- **Core Type Definitions:** Define TypeScript interfaces for `AgentState` (id, type, status, currentTask, metadata), `TaskState` (id, phaseId, status, assignedAgent, dependencies, startTime, completionTime), `SessionState` (id, projectId, startTime, pauseTime, checkpoints, activeAgents), and `StateTransition` (fromState, toState, timestamp, trigger, metadata). Define strict enums for `AgentType` (Manager, Implementation, AdHoc), `AgentStatus` (Spawning, Active, Waiting, Idle, Terminated), `TaskStatus` (Pending, Assigned, InProgress, Blocked, Completed, Failed), and `SessionStatus` (Initializing, Running, Paused, Completed, Failed). Use discriminated unions for polymorphic state variants.

- **State Enum Definitions:** Create comprehensive enums for all state values ensuring exhaustive type checking: agent lifecycle states (spawn → active → waiting/idle → terminated), task execution states (pending → assigned → in_progress → completed/failed), session states (init → running → paused → completed), transition trigger types (user action, automatic, timeout, error), and agent domain types matching Implementation Plan assignments (Orchestration_Foundation, Orchestration_CLI, Communication, etc.). Export const enums for compile-time inlining where appropriate.

- **Validation and Schema Export:** Implement runtime type validation using zod schemas matching TypeScript interfaces for data integrity at system boundaries (API inputs, database reads, file parsing). Export validation functions (`validateAgentState`, `validateTaskState`, `validateSessionState`) for use in database operations and API handlers. Create schema export utilities to generate database column type definitions from TypeScript types, ensuring database schema (Task 1.1) stays synchronized with type system. Implement type guards for safe type narrowing in conditional logic.

### Task 1.4 – Database Migration Infrastructure │ Agent_Orchestration_Foundation

- **Objective:** Create robust database migration framework enabling schema evolution through version-controlled migration scripts, supporting both forward migrations (up) and rollback (down) with comprehensive migration history tracking and CLI integration.
- **Output:** Migration framework with TypeScript migration definition format, version tracking system integrated with state database, CLI commands for migration management (`apm-auto migrate up/down/list`), and test suite validating migration execution, rollback, and version consistency.
- **Guidance:** Depends on Task 1.1 Output. Build migration framework supporting the schema created in Task 1.1 and enabling future evolution. Store migrations in versioned files (`migrations/001_initial_schema.ts`, `migrations/002_add_worktree_table.ts`, etc.). Use timestamp-based or sequential versioning. Track applied migrations in dedicated `schema_migrations` table. Follow TDD—write tests for migration up/down execution before implementing framework. Ensure migrations are atomic (wrapped in transactions) and idempotent where possible.

1. **Migration Framework Core:** Implement migration framework with TypeScript migration file format defining `up()` and `down()` functions for schema changes. Create `MigrationRunner` class handling migration discovery (scanning `migrations/` directory), execution sequencing (applying unapplied migrations in order), transaction management (atomic migration application with rollback on failure), and error reporting. Support both programmatic execution and CLI invocation. Implement dry-run mode for migration preview without execution.

2. **Version Tracking System:** Create `schema_migrations` table tracking migration history with columns: migration_name, applied_at timestamp, and execution_duration. Implement migration state manager querying applied migrations, determining pending migrations by comparing filesystem to database, and recording successful migration application. Add migration checksum validation to detect modified migration files after application. Implement migration locking to prevent concurrent migration execution in multi-process environments.

3. **CLI Integration:** Extend apm-auto CLI (from Phase 2, Task 2.1) with migration commands: `apm-auto migrate up` (apply pending migrations), `apm-auto migrate down` (rollback last migration), `apm-auto migrate list` (show migration status), `apm-auto migrate create <name>` (generate new migration file from template). Commands use database connection from Task 1.1 connection manager. Provide verbose output showing migration progress and results. Support --dry-run flag for migration preview.

4. **Migration Testing:** Write comprehensive test suite covering migration up execution (schema changes applied correctly), migration down rollback (schema changes reversed correctly), version tracking accuracy (applied migrations recorded in schema_migrations table), idempotency (re-running migrations safe), error handling (failed migrations don't corrupt database state, transaction rollback works), and CLI command integration (all migration commands execute properly). Test with multiple sequential migrations to validate ordering. Achieve 80% coverage minimum with 100% pass rate.

## Phase 2: CLI & Orchestration Core

### Task 2.1 – CLI Structure and Command Framework │ Agent_Orchestration_CLI

- **Objective:** Build the apm-auto command-line interface foundation using Commander.js to provide a consistent, user-friendly command structure matching existing apm tool conventions while supporting all automation lifecycle operations.
- **Output:** Complete CLI entry point with command registration, help text, version information, and option parsing framework ready for command implementation in subsequent tasks and phases.
- **Guidance:** Follow patterns from existing apm CLI tool for consistency (Commander.js, chalk for colors, Inquirer for prompts). Implement base commands (`start`, `stop`, `status`, `resume`) with placeholder handlers to be fully implemented by Phase 4 Agent Automation tasks. Use conventional command structure with global options (--verbose, --config, --help). Provide comprehensive help text following standard CLI UX best practices. Support both interactive and non-interactive modes for CI/CD compatibility.

- **CLI Entry Point Creation:** Initialize apm-auto CLI entry point using Commander.js framework matching existing `apm` tool architecture patterns. Configure package.json bin entry for global command installation. Implement command loader discovering and registering all available commands. Add global option parsing (--verbose for detailed output, --config for custom config file path, --no-color to disable chalk output). Set up logging infrastructure with configurable log levels (error, warn, info, debug) using a library like winston or pino. Implement graceful shutdown handling for SIGINT/SIGTERM signals.

- **Base Command Structure:** Register core lifecycle commands with Commander: `apm-auto start [scope]` (begin automation for specified scope), `apm-auto stop` (gracefully terminate running automation), `apm-auto status` (show current automation state), `apm-auto resume` (continue paused session). Each command includes short description, usage examples, and option definitions. Implement placeholder command handlers that validate inputs and print "Not yet implemented" messages. Add command aliases for convenience (e.g., `run` as alias for `start`). Ensure commands follow conventional CLI exit codes (0 success, 1 error, 2 usage error).

- **Help and Version Information:** Implement comprehensive help system using Commander's built-in help generation enhanced with custom formatting. Add `--help` global flag and `help [command]` subcommand showing detailed command usage, all available options, usage examples, and related commands. Implement `--version` flag displaying apm-auto version from package.json with additional build information (commit hash, build date). Create structured help text following standard CLI conventions with consistent formatting, clear option descriptions, and practical usage examples. Support both brief and detailed help modes.

- **Option Parsing and Validation Framework:** Configure Commander option parsing with type coercion (string, number, boolean), variadic arguments support, and custom option processors for complex types (e.g., parsing scope definitions). Implement option validation framework checking required options presence, value constraints (ranges, enums), and conflicting option combinations. Provide clear, actionable error messages for validation failures with suggested corrections. Support environment variable overrides for options (e.g., APM_AUTO_CONFIG_PATH). Implement option value normalization (path resolution, case normalization) for consistent internal handling.

### Task 2.2 – Scope Definition and Parsing Logic │ Agent_Orchestration_CLI

- **Objective:** Implement Implementation Plan scope parsing extracting phase ranges, task lists, and agent assignments from YAML frontmatter to enable precise work boundaries for automated execution sessions.
- **Output:** Scope parser module with YAML frontmatter extractor, scope definition data structures, task filtering logic, and comprehensive test suite validating accurate scope parsing and task selection from Implementation Plan files.
- **Guidance:** Parse YAML frontmatter from Implementation Plan markdown files (format: `---\nscope: phase:1-3\ntasks: [1.1, 1.2, 2.1]\n---`). Support multiple scope specification formats (phase ranges, task lists, agent filters, tag-based selection). Integrate with database layer (Task 1.1) to validate scope references valid phases/tasks. Follow TDD methodology. Handle malformed YAML gracefully with helpful error messages. Cache parsed scopes for performance.

1. **YAML Frontmatter Parser:** Implement robust YAML parser extracting frontmatter from Implementation Plan markdown files using `gray-matter` or similar library. Support standard YAML frontmatter delimiters (`---` at start/end). Parse scope definition fields: `phase` (single or range like "1-3"), `tasks` (array of task IDs like ["1.1", "2.3"]), `agents` (agent domain filter), `tags` (custom tag filters). Validate YAML syntax providing clear error messages for malformed frontmatter. Handle edge cases (no frontmatter, invalid YAML, missing scope fields) gracefully with informative warnings.

2. **Scope Definition Extraction:** Create `ScopeDefinition` data structure with typed fields: phaseRange (start/end phase numbers), taskList (array of task IDs), agentFilters (array of agent domain names), customFilters (extensible filter criteria). Implement scope parser converting YAML frontmatter to `ScopeDefinition` instances with validation against Implementation Plan structure. Support scope combinators (union, intersection) for complex selections like "phase 1-2 AND agent:Orchestration*". Resolve wildcard patterns (*) in agent filters. Provide scope summary method generating human-readable description for user confirmation.

3. **Task Filtering Logic:** Implement task filter applying `ScopeDefinition` to Implementation Plan structure, returning filtered task list matching scope criteria. Filter by phase range (include all tasks in specified phases), explicit task IDs (include specific tasks), agent assignments (include tasks assigned to matching agents), dependency constraints (include dependent tasks if dependencies are in scope). Respect task dependencies—if scope includes task X depending on task Y, automatically include Y or warn user. Support "dry-run" mode showing which tasks would be selected without executing. Export filtered task list with full task metadata for execution planning.

4. **Scope Validation and Testing:** Write comprehensive test suite covering YAML parsing (valid frontmatter, malformed YAML, edge cases), scope extraction (various scope formats, wildcards, combinators), task filtering accuracy (phase ranges select correct tasks, task lists exact match, agent filters work correctly, dependency inclusion), error handling (invalid phase numbers, non-existent task IDs, conflicting filters), and integration with Implementation Plan structure. Test with realistic Implementation Plan samples. Achieve 80% coverage minimum with 100% pass rate.

### Task 2.3 – Agent Lifecycle State Management │ Agent_Orchestration_CLI

- **Objective:** Implement comprehensive agent lifecycle state tracking managing state transitions from spawn through active/waiting/idle to terminated states with database persistence and event handling for coordination.
- **Output:** Agent lifecycle state manager with state transition logic, database persistence layer, lifecycle event handlers, recovery logic for crashed agents, and complete test suite validating state management reliability.
- **Guidance:** Depends on Task 2.1 Output and Task 1.1 Output by Agent_Orchestration_Foundation. Implement state machine for agent lifecycle using TypeScript enums from Task 1.3. Persist state transitions to database using connection from Task 1.1. Emit lifecycle events (AgentSpawned, AgentActive, AgentWaiting, AgentTerminated) for coordination. Support recovery from crashed agents (detect unresponsive state, attempt restart, escalate to user if fails). Follow TDD methodology. Ensure state transitions are atomic using database transactions.

1. **State Transition Definitions:** Define agent lifecycle state machine with explicit transitions: `null → Spawning` (agent creation initiated), `Spawning → Active` (agent ready and working), `Active → Waiting` (agent idle awaiting work/input), `Waiting → Active` (agent resumed work), `Active/Waiting → Idle` (agent temporarily paused), `Idle → Active` (agent resumed from pause), `any → Terminated` (agent shutdown/crashed). Implement state transition validation preventing invalid transitions (e.g., Terminated → Active). Use TypeScript enums from Task 1.3 for type safety. Create transition guard functions checking preconditions before allowing state changes. Document each transition's trigger conditions and effects.

2. **Database Persistence Layer:** Implement state persistence using database connection manager from Task 1.1. Create `agent_states` table storing agent_id, current_state, state_metadata (JSON), last_transition_timestamp, and heartbeat_timestamp. Implement state update functions executing atomic updates within transactions to prevent race conditions. Add state history tracking in `agent_state_transitions` table recording all state changes with transition triggers and metadata for audit trail. Implement state query functions retrieving current state, state history, and agent statistics (time in each state, transition counts). Add database indexes for efficient state queries.

3. **Lifecycle Event Handlers:** Implement event emitter for lifecycle events using Node.js EventEmitter or similar. Emit events for all state transitions: `agent:spawning`, `agent:active`, `agent:waiting`, `agent:idle`, `agent:terminated`. Include event payload with agent ID, state transition details, timestamp, and contextual metadata. Create event handler registration system allowing other modules to subscribe to lifecycle events for coordination (e.g., Manager agent listens for Implementation agent state changes). Implement event buffering during database unavailability to ensure no events lost. Add event replay capability for debugging and recovery scenarios.

4. **Crashed Agent Recovery Logic:** Implement agent health monitoring checking heartbeat timestamps to detect unresponsive agents. Define crashed state detection criteria (no heartbeat for N seconds, process exit detected, unhandled error in agent output). Create automatic recovery workflow: detect crashed state → mark agent as Terminated → attempt automatic restart using spawn logic from Phase 4 Task 4.1 → restore agent context from last checkpoint → transition to Active if restart succeeds. Implement recovery retry limits (max 3 attempts) with exponential backoff between retries. Escalate to user notification if recovery fails after max attempts. Log all recovery attempts with detailed diagnostics.

5. **State Management Testing:** Write comprehensive test suite covering state transition validation (all valid transitions allowed, invalid transitions rejected), database persistence (state updates atomic, history tracked correctly), concurrent state updates (race conditions handled), event emission (all transitions emit events, event handlers receive events), heartbeat monitoring (crashed agents detected, recovery triggered), recovery logic (restart attempts work, retry limits enforced, escalation occurs), and integration with database layer from Task 1.1. Mock database for unit tests, use real database for integration tests. Achieve 80% coverage minimum with 100% pass rate.

### Task 2.4 – Configuration Management System │ Agent_Orchestration_CLI

- **Objective:** Create user configuration management system supporting autonomy levels, resource limits, and customizable preferences through YAML-based configuration files with schema validation and sensible defaults.
- **Output:** Configuration management module with typed configuration schema, YAML file loading logic, validation framework, default configuration, user override merging, and helpful error messages for invalid settings.
- **Guidance:** Depends on Task 2.1 Output. Store configuration in `~/.apm-auto/config.yml` and project-local `.apm-auto/config.yml` with project config overriding global. Define configuration schema using TypeScript types from Task 1.3 and zod validation. Support autonomy levels (Cautious/Automated/YOLO from v3 Phase 10), resource limits (max agents, max worktrees), logging preferences, notification settings. Follow convention-over-configuration principle with sensible defaults. Validate config on load with clear error messages. Support environment variable overrides.

- **Configuration Schema Definition:** Define comprehensive configuration schema using TypeScript interfaces: `AutonomyConfig` (level: Cautious|Automated|YOLO, approvalThresholds), `ResourceConfig` (maxAgents: number, maxWorktrees: number, tokenBudget: number), `LoggingConfig` (level: debug|info|warn|error, file path, console output), `NotificationConfig` (enabled: boolean, channels: string[]). Create zod schemas matching TypeScript types for runtime validation. Export configuration type as union of all config sections. Document each configuration option with description, valid values, and default. Organize schema logically by functional area matching user mental model.

- **YAML File Loading with Validation:** Implement configuration file loader discovering config files in precedence order: environment variables → project-local `.apm-auto/config.yml` → global `~/.apm-auto/config.yml` → built-in defaults. Use `js-yaml` library for YAML parsing with schema validation. Load each config file validating against zod schemas, accumulating validation errors for comprehensive error reporting. Merge configurations following precedence rules (env vars highest priority, built-in defaults lowest). Handle missing config files gracefully (use defaults, log info message). Parse environment variable overrides with prefix `APM_AUTO_` (e.g., `APM_AUTO_AUTONOMY_LEVEL=YOLO`).

- **Default Configuration and User Override Merging:** Define sensible default configuration covering all required settings: autonomy level (Cautious for safety), resource limits (10 max agents, 20 max worktrees per Context Synthesis), logging (info level, console output), notifications (disabled initially). Implement deep merge logic combining user configuration with defaults, preserving user-specified values and filling gaps with defaults. Support partial configuration (user only specifies settings they want to change). Validate merged configuration ensuring all required fields present and constraints satisfied. Export final merged config as strongly-typed object for use throughout application.

- **Validation and Error Messaging:** Implement configuration validation using zod schemas with custom error messages. Check constraint violations: autonomy level is valid enum value, resource limits are positive integers within reasonable bounds (max agents ≤ 100, max worktrees ≤ 50), file paths exist and are writable, notification channels are supported. Generate actionable error messages for validation failures including invalid field path, expected vs actual value, suggested fix, and documentation reference. Aggregate multiple validation errors into single user-friendly error report. Support `apm-auto config validate` command checking config without loading. Add `apm-auto config show` command displaying current merged configuration.

## Phase 3: Communication Protocol

### Task 3.1 – Protocol Design & Specification │ Agent_Communication

- **Objective:** Design comprehensive inter-agent communication protocol specification enabling WebSocket-like log-styled messaging between Claude Code agent processes with message routing, acknowledgments, and reliable delivery semantics.
- **Output:** Complete protocol specification document detailing message types, format schemas, routing rules, acknowledgment mechanisms, and error handling procedures, ready for implementation in subsequent communication tasks.
- **Guidance:** Requires ad-hoc delegation for research into WebSocket-like patterns and log-styled messaging approaches suitable for file-based agent coordination. Protocol must support Manager↔Implementation agent coordination, cross-agent task handoffs, and state synchronization. Design for eventual consistency given file-based communication latency. Document message lifecycle (creation→routing→delivery→acknowledgment). Support both request-response and publish-subscribe patterns. Enable message prioritization for urgent coordinator messages.

1. **Ad-Hoc Delegation – Research Communication Patterns:** Delegate to Ad-Hoc research agent to investigate WebSocket-like communication patterns adaptable to file-based systems, log-styled messaging architectures for agent coordination, message queue designs supporting file persistence, and inter-process communication best practices for loosely-coupled agents. Research should identify trade-offs between polling vs file watching, message ordering guarantees, and handling of network partition scenarios (file locks, concurrent writes). Output research findings document with pattern recommendations.

2. **Protocol Specification Design:** Define comprehensive protocol specification based on research findings. Specify message envelope format (sender/receiver IDs, message type, timestamp, correlation ID, payload). Define message types: TASK_ASSIGNMENT (Manager→Implementation), TASK_UPDATE (Implementation→Manager progress), STATE_SYNC (state replication), ERROR_REPORT (failure notification), HANDOFF_REQUEST (cross-agent coordination), ACK/NACK (acknowledgments). Specify routing rules determining message delivery paths. Define message lifecycle states (pending, in-transit, delivered, acknowledged, failed). Document protocol versioning strategy for future evolution.

3. **Message Format and Serialization Schema:** Design JSON-based message format with strongly-typed payload schemas. Define message envelope schema: `{ version, messageId, correlationId, sender: { agentId, type }, receiver: { agentId, type }, messageType, timestamp, priority, payload: { ... }, metadata: { ... } }`. Create payload schemas for each message type using JSON Schema for validation. Specify serialization rules (UTF-8 encoding, newline-delimited JSON for log files, optional compression for large payloads). Define schema versioning and backward compatibility guarantees. Export TypeScript types matching JSON schemas.

4. **Validation Schema and Error Handling:** Create comprehensive validation schemas for protocol messages using JSON Schema with custom validators for business rules. Implement validation levels: syntax (valid JSON), schema (matches message type schema), semantic (business rules like valid agent IDs). Define error codes and error message format for validation failures. Specify error handling procedures: malformed messages → logged and dropped, schema violations → NACK with error details, semantic errors → ERROR_REPORT to sender. Document retry policies for transient failures. Define dead letter queue handling for permanently failed messages.

5. **Protocol Documentation:** Generate complete protocol specification document including protocol overview and goals, message type catalog with examples, routing algorithm specification, acknowledgment semantics, error handling procedures, sequence diagrams for common flows (task assignment, progress updates, handoffs), performance characteristics (latency expectations, throughput limits), and extension points for future protocol evolution. Format documentation as formal specification suitable for implementation team reference. Include test scenarios for protocol compliance validation.

### Task 3.2 – Message Passing Implementation │ Agent_Communication

- **Objective:** Implement robust message passing layer supporting protocol message queue management, serialization/deserialization, delivery confirmation, and error handling with retry logic according to protocol specification.
- **Output:** Message passing module with priority queue implementation, JSON serialization layer, delivery confirmation tracking, retry logic with exponential backoff, and dead letter queue for failed messages.
- **Guidance:** Depends on Task 3.1 Output. Implement in-memory message queue backed by file persistence for durability across restarts. Use protocol specification from Task 3.1 for message format validation. Support priority levels (high/normal/low) for message routing. Implement delivery confirmation with configurable timeout. Handle concurrent message processing using async patterns. Follow TDD methodology. Ensure thread-safe queue operations for multi-agent concurrency.

1. **Message Queue with Priority Handling:** Implement priority queue data structure using heap-based priority queue or similar efficient structure. Support three priority levels: HIGH (urgent coordinator messages, error reports), NORMAL (standard task updates, state sync), LOW (background housekeeping, audit logs). Implement queue operations: enqueue (add message with priority), dequeue (retrieve highest priority message), peek (inspect queue head without removal), clear (empty queue). Add queue persistence to file for durability (append-only log format). Implement queue recovery on startup reading persisted messages. Support queue size limits with overflow handling (reject new messages or drop lowest priority).

2. **Message Serialization and Deserialization Layer:** Implement message serializer converting protocol message objects to JSON strings following Task 3.1 format specification. Use TypeScript types from protocol spec for type safety. Implement schema validation during serialization ensuring outgoing messages conform to protocol. Create deserializer parsing JSON strings to typed message objects with validation against message type schemas. Handle deserialization errors gracefully (log parse error, return error result, don't crash process). Support optional message compression for large payloads using gzip. Add message size limits preventing memory exhaustion. Implement serialization performance optimization (object pooling, string builder patterns).

3. **Delivery Confirmation and Retry Logic:** Implement delivery tracking system recording sent messages awaiting acknowledgment. Associate each sent message with delivery timeout (configurable per message priority). Create acknowledgment handler processing ACK/NACK messages from receivers, updating delivery status. Implement retry logic for unacknowledged messages: retry up to 3 times with exponential backoff (1s, 2s, 4s delays). Track retry attempts per message. After max retries exceeded, move message to dead letter queue. Support manual retry from dead letter queue. Emit delivery events (sent, acknowledged, failed) for monitoring. Persist delivery state to survive process restarts.

4. **Error Handling and Dead Letter Queue:** Create dead letter queue (DLQ) capturing permanently failed messages for forensic analysis. Failed message criteria: max retries exceeded, receiver agent terminated, message schema validation failed after repeated attempts. Store DLQ messages with failure metadata (failure reason, retry count, timestamps, error details). Implement DLQ management operations: list failed messages, inspect message details, manual retry, manual discard. Add DLQ monitoring alerting when threshold exceeded (e.g., >10 messages in DLQ). Provide DLQ export functionality for offline analysis. Implement DLQ size limits with automatic purging of oldest entries. Log all DLQ operations to audit trail.

### Task 3.3 – Memory File Monitoring │ Agent_Communication

- **Objective:** Implement robust .apm/ directory file monitoring system detecting memory log changes, parsing task completion status, and triggering state machine updates with debouncing to prevent spurious updates from rapid file changes.
- **Output:** File watcher module monitoring .apm/ directory tree, change detection logic with debouncing, memory log parser extracting completion status, and event emitter integrating file changes with state machine.
- **Guidance:** Depends on Task 3.1 Output. Use Node.js fs.watch or chokidar library for cross-platform file watching. Monitor .apm/Memory/ directory recursively for task memory log files. Debounce rapid changes (wait 500ms after last change before processing). Parse memory logs to detect task completion markers. Emit state update events consumed by Task 2.3 lifecycle management. Handle edge cases (file creation, deletion, rapid updates, file locks). Follow TDD with mocked filesystem for unit tests.

1. **File Watcher Implementation:** Implement file watcher for .apm/Memory/ directory using chokidar library for reliable cross-platform file watching. Configure watcher to monitor recursively all subdirectories for task phase memory logs. Watch for file events: add (new memory log created), change (log updated with progress), unlink (log deleted). Implement watcher startup discovering existing files for initial state. Handle watcher errors gracefully (log error, attempt restart after delay). Support watcher pause/resume for manual file operations. Add watcher status monitoring (active, paused, error states). Emit raw file events for downstream processing.

2. **Change Detection with Debouncing:** Implement debouncing logic accumulating rapid file changes and emitting single change event after quiet period. Configure debounce delay (500ms default, configurable per Context Synthesis). Track pending changes per file (last change timestamp, change type). Timer-based debounce: reset timer on each change, emit event when timer expires. Batch related changes (multiple changes to same file collapsed to single event). Handle edge cases: file deleted before debounce completes (emit deletion event), file changed during parsing (retry after next change). Support immediate mode for critical files (no debouncing for certain patterns).

3. **Memory Log Parsing:** Implement memory log parser extracting task status from .apm/ markdown files. Parse memory log format matching APM Memory_Log_Guide.md structure: task ID, status markers (Started, In Progress, Completed, Blocked), progress notes, error messages. Use markdown parser (marked or similar) for structured parsing. Extract completion status from specific markers (## Status: Completed, ## Blockers: [reason]). Map memory log status to apm-auto task states (InProgress, Completed, Blocked, Failed). Handle incomplete logs gracefully (assume in-progress if status ambiguous). Validate parsed data against expected format. Return structured parse result with task ID, status, progress percentage, blockers, completion timestamp.

4. **State Machine Event Integration:** Integrate memory file events with state machine from Task 2.3. Map file change events to state updates: new memory log → task started (update to InProgress), log completion marker → task completed (update to Completed), blocker detected → task blocked (update to Blocked, notify Manager). Emit state update events with parsed data payload. Subscribe to state update events in lifecycle manager (Task 2.3) for database persistence. Implement event ordering guarantees ensuring state updates processed in change order. Handle concurrent events from multiple agents (queue events, process sequentially). Add event replay buffer for debugging state transitions. Test event integration end-to-end with real .apm/ file operations.

### Task 3.4 – Event Bus and Message Routing │ Agent_Communication

- **Objective:** Implement central event bus coordinating all agent communication events with topic-based message routing, subscription management for event listeners, and comprehensive testing validating event delivery reliability.
- **Output:** Event bus module with topic-based publish-subscribe functionality, message routing rules engine, subscription lifecycle management, and complete test suite validating event bus reliability and performance.
- **Guidance:** Depends on Task 3.1 Output. Implement event bus using Node.js EventEmitter or purpose-built event bus library (like EventEmitter2 for wildcard support). Support topic-based routing (agent:*, task:*, state:* patterns). Allow multiple subscribers per topic. Guarantee event delivery to all subscribers. Support synchronous and asynchronous event handlers. Add event history buffer for replay. Follow TDD with comprehensive event bus behavior tests.

- **Event Bus Core Implementation:** Create central event bus instance using EventEmitter2 for wildcard topic support. Implement publish method accepting topic string (e.g., "agent:spawned", "task:completed:1.2") and event data payload. Route published events to all subscribers matching topic pattern. Support wildcard subscriptions ("agent:*" matches all agent events, "**" matches everything). Guarantee delivery order (FIFO per topic). Implement event emission modes: sync (await all handlers before returning), async (fire-and-forget), broadcast (emit to all subscribers regardless of topic). Add event metadata (timestamp, publisher ID, event ID) to all published events. Support event cancellation for special cases.

- **Message Routing Logic:** Implement routing rules engine mapping event topics to subscriber callbacks. Maintain subscription registry: Map<topic_pattern, Set<subscriber_callbacks>>. On publish, match topic against all patterns using wildcard matching algorithm. Invoke matched subscriber callbacks with event data. Support routing rules: exact match (topic == pattern), prefix match (topic starts with pattern), wildcard match (pattern contains * or **), regex patterns (advanced use cases). Implement routing priority levels allowing high-priority subscribers to receive events first. Add routing statistics (messages routed per topic, subscriber invocation counts). Support dynamic routing rule updates without event bus restart.

- **Subscription Management:** Implement subscription lifecycle operations: subscribe (register callback for topic), unsubscribe (remove callback), unsubscribeAll (clear all subscriptions for subscriber). Return subscription handle from subscribe enabling targeted unsubscribe. Track subscriber metadata (subscriber ID, subscription time, callback reference). Implement subscriber groups allowing bulk subscribe/unsubscribe operations. Support once subscriptions (auto-unsubscribe after first event). Add subscription expiry (TTL-based auto-unsubscribe). Implement subscription validation preventing duplicate subscriptions. Provide subscription introspection (list active subscriptions per topic, find subscribers for agent).

- **Event Bus Testing:** Write comprehensive test suite covering event publication (events delivered to subscribers, wildcards work correctly, event data preserved), subscription management (subscribe/unsubscribe work, once subscriptions auto-remove, subscription handles valid), routing logic (topic matching accurate, priority respected, no events lost), concurrent operations (thread-safe pub/sub, no race conditions), error handling (subscriber exceptions don't stop delivery to other subscribers, error events emitted), and performance (handle high event throughput, subscription registry efficient). Test with realistic event patterns from agent coordination scenarios. Achieve 80% coverage minimum with 100% pass rate.

## Phase 4: Agent Automation

### Task 4.1 – Claude Code Agent Spawning │ Agent_Orchestration_Automation

- **Objective:** Integrate Claude Code CLI to programmatically spawn Manager and Implementation agents, capturing their output streams, tracking spawned processes in state database, and handling spawn failures with robust error recovery.
- **Output:** Agent spawning module with Claude CLI integration, process management for spawned agents, prompt template system for agent initialization, agent process tracking in database, and comprehensive error handling for spawn failures.
- **Guidance:** Depends on Task 1.1 Output by Agent_Orchestration_Foundation. Use Node.js child_process to execute `claude 'prompt'` commands spawning new agent instances. Capture stdout/stderr for logging and debugging. Create prompt templates for Manager and Implementation agents including task context, memory log paths, and coordination instructions. Track spawned processes in database using agent_states table from Task 1.1. Handle spawn failures (CLI not found, permission errors, timeout) with clear error messages. Follow TDD with mocked child_process for unit tests.

1. **Claude Code CLI Integration:** Implement Claude CLI wrapper executing `claude 'prompt'` commands via Node.js child_process.spawn. Validate Claude CLI availability on PATH before spawning (check `which claude` on Linux/macOS, `where claude` on Windows). Configure spawn options: shell execution for proper command parsing, inherit stdio for debugging mode, pipe stdio for production capturing. Set spawn timeout (5 minutes default) preventing hung processes. Implement environment variable passing to Claude processes (API keys, config paths). Add spawn retry logic for transient failures (3 retries with 5s delay). Log all spawn attempts with command, arguments, and spawn result.

2. **Process Spawning and Output Capture:** Implement process spawning with proper stream handling. Capture stdout streaming agent output for logging and progress monitoring. Capture stderr for error detection and diagnostic logging. Buffer output with size limits preventing memory exhaustion (max 10MB per stream). Parse output for agent status markers (READY, ERROR, COMPLETE) using regex patterns. Implement process lifecycle tracking: spawned → running → exited/failed. Monitor process exit codes and signals (0=success, >0=error, SIGTERM/SIGKILL=terminated). Handle child process cleanup preventing zombie processes. Support graceful termination sending SIGTERM before SIGKILL. Emit process events (spawned, output, error, exit) for coordination.

3. **Prompt Templating System:** Create prompt template engine for Manager and Implementation agent initialization prompts. Define template structure: agent role description, task context (from Implementation Plan), memory log paths (.apm/Memory/Phase_XX/Task_XX.md), coordination instructions (how to signal completion, report blockers), constitutional principles (TDD, conventional commits, quality gates). Implement template variables: {{AGENT_TYPE}}, {{TASK_ID}}, {{TASK_OBJECTIVE}}, {{DEPENDENCIES}}, {{MEMORY_PATH}}. Support template composition (base agent template + task-specific template). Validate rendered prompts ensuring all variables populated. Store templates in templates/ directory with version control. Export template rendering function accepting task context and returning prompt string ready for Claude CLI.

4. **Agent Process Tracking:** Integrate with database layer (Task 1.1) tracking spawned agent processes. Record agent metadata in agent_states table: process_id, spawn_time, prompt_template_id, task_assignment. Update agent state on spawn events: null→Spawning→Active. Track process health via periodic heartbeat checks (agent process still running, responding to signals). Implement process recovery detection (agent exited unexpectedly, needs restart from Task 2.3 recovery logic). Query active agent processes for monitoring and coordination. Support bulk operations (list all active agents, terminate all agents for phase). Add agent process metrics (CPU usage, memory consumption, runtime duration) for resource monitoring.

5. **Spawn Error Handling:** Implement comprehensive error handling for spawn failures. Detect error conditions: Claude CLI not found on PATH (command not found error), insufficient permissions (EACCES error), spawn timeout exceeded (process hung), invalid prompt (Claude CLI rejects malformed input), resource exhaustion (too many processes, out of memory). Generate actionable error messages with resolution guidance: CLI not found→install instructions, permissions→chmod guidance, timeout→increase timeout or check prompt complexity, invalid prompt→show validation errors. Log all errors with full diagnostic context (command, args, environment, error message, stack trace). Retry transient errors automatically. Escalate persistent errors to user notification. Test error scenarios with mocked failures ensuring graceful degradation.

### Task 4.2 – Manager Agent Orchestration │ Agent_Orchestration_Automation

- **Objective:** Implement Manager agent orchestration logic generating Task Assignment Prompts from Implementation Plan, selecting appropriate agents for task execution, resolving task dependencies, coordinating cross-agent handoffs, monitoring progress via memory logs, and detecting handover triggers based on context window thresholds.
- **Output:** Manager orchestration module with Task Assignment Prompt generator, agent selection algorithm, dependency resolution engine, cross-agent coordination logic, progress monitoring system, and handover detection mechanism.
- **Guidance:** Depends on Task 4.1 Output and Task 2.2 Output by Agent_Orchestration_CLI. Manager agent is the central coordinator spawning and managing Implementation agents. Generate Task Assignment Prompts from Implementation Plan tasks using prompt templates. Select agents based on task domain assignments from plan. Resolve dependencies ensuring prerequisite tasks complete before dependent tasks start. Monitor progress through memory log polling (Task 3.3). Detect handover triggers (context >80% capacity, explicit handover markers in memory logs). Follow TDD with comprehensive orchestration scenario tests.

1. **Task Assignment Prompt Generation:** Implement Task Assignment Prompt generator creating comprehensive prompts for Implementation agents. Extract task details from Implementation Plan: task ID, objective, output specifications, guidance, subtask steps, dependencies. Compose prompt using template from Task 4.1 including: task objective and scope, detailed execution steps (from Implementation Plan subtasks), dependency information (prerequisite task outputs, cross-agent coordination needs), output specifications (expected deliverables, validation criteria), memory log instructions (log format, status markers, completion signals), constitutional requirements (TDD, coverage thresholds, quality gates). Render prompt template populating all variables. Validate generated prompt ensuring completeness (no missing variables, all dependencies referenced, output specs clear). Return prompt string ready for agent spawning.

2. **Agent Selection Logic:** Implement agent selection algorithm determining which Implementation agent executes each task. Parse agent assignments from Implementation Plan (Agent_Orchestration_Foundation, Agent_Communication, etc.). Match task agent assignment to available agent pool. Handle agent reuse (if agent idle, assign new task to existing agent process vs spawn new agent). Consider agent specialization (some tasks require specific agent types like Ad-Hoc for research). Implement agent load balancing preventing single agent overload (distribute tasks across multiple agents of same type if parallel execution possible). Support agent affinity (prefer assigning related tasks to same agent for context continuity). Query agent availability from database (Task 2.3 lifecycle states). Log agent selection decisions for audit trail.

3. **Dependency Resolution Engine:** Implement dependency resolution determining task execution order. Parse task dependencies from Implementation Plan (Task X.Y depends on Task Z.W). Build dependency graph (directed acyclic graph) representing task prerequisites. Detect dependency cycles warning user of invalid plan. Implement topological sort determining valid execution order. Identify tasks ready for execution (all dependencies satisfied, no blockers). Support parallel execution (independent tasks can run concurrently). Handle cross-agent dependencies (Task by Agent A depends on Task by Agent B, coordinate handoff). Queue dependent tasks until prerequisites complete. Update ready task list as tasks complete. Emit dependency events (task_ready, dependency_satisfied) for coordination.

4. **Cross-Agent Coordination Logic:** Implement cross-agent handoff coordination for tasks with dependencies spanning multiple agents. Detect cross-agent dependencies (producer and consumer tasks assigned to different agents). Generate handoff messages using communication protocol (Task 3.1) with dependency output data. Track handoff status (initiated, data_transferred, acknowledged, completed). Implement handoff timeout handling (handoff not acknowledged within threshold, escalate to user). Support synchronous handoffs (consumer agent waits for producer completion) and asynchronous handoffs (consumer agent proceeds with cached data). Log all handoffs for audit trail. Handle handoff failures (producer agent crashed, data corruption, network issues) with retry and escalation logic.

5. **Progress Monitoring via Memory Logs:** Integrate with memory file monitoring (Task 3.3) tracking Implementation agent progress. Subscribe to memory log change events for assigned tasks. Parse progress updates from memory logs (status markers, completion percentage, blockers). Update task state in database reflecting current progress. Detect task completion (memory log contains completion marker). Detect task blockers (memory log contains blocker description, escalate to user). Implement progress timeout (task shows no progress for N minutes, investigate potential hang). Generate progress reports for user visibility (X% complete, current task, recent updates). Support progress queries (get status for task/phase, estimate time remaining).

6. **Handover Detection Logic:** Implement context window monitoring detecting when agents approach token limits requiring handover. Estimate token usage from memory log length, conversation history size, and task complexity. Define handover threshold (80% of context window capacity per Context Synthesis). Detect handover triggers: context threshold exceeded, explicit handover marker in memory log (agent requests handover), task completion natural handover point (end of task/phase). Generate handover prompt for new agent instance including current context summary, task progress, next steps. Coordinate handover transition (pause old agent, spawn new agent with handover prompt, transfer state). Log all handovers for audit and debugging. Test handover scenarios ensuring smooth transitions.

### Task 4.3 – Implementation Agent Execution │ Agent_Orchestration_Automation

- **Objective:** Implement Implementation agent execution logic enabling agents to receive task assignments, execute work following Task Assignment Prompt instructions, generate memory logs documenting progress, report completion to Manager agent, and escalate errors or blockers for Manager intervention.
- **Output:** Implementation agent execution framework with task receipt handler, execution monitoring system, memory log generation validator, completion reporting mechanism, and error escalation logic.
- **Guidance:** Depends on Task 4.2 Output. Implementation agents execute tasks assigned by Manager. Parse Task Assignment Prompts extracting task details and execution steps. Generate memory logs following APM Memory_Log_Guide.md format. Update memory logs with progress, blockers, completion markers. Monitor execution for errors and blockers. Report completion via memory log completion marker (Manager monitors via Task 4.2). Escalate blockers to Manager for user intervention. Follow TDD testing execution scenarios with mocked agent behavior.

1. **Task Receipt and Parsing:** Implement task receipt handler processing Task Assignment Prompts from Manager agent (spawned via Task 4.1). Parse prompt extracting task metadata (task ID, objective, output specs, execution steps, dependencies, memory log path). Validate received task assignment ensuring all required fields present and valid. Load dependency data from prerequisite tasks (read dependency outputs from completed task memory logs). Initialize execution context with task details, dependencies, configuration. Create memory log file at specified path with initial entries (task ID, start timestamp, objective). Acknowledge task receipt to Manager (via completion of initialization, memory log created). Transition agent state to Active (via lifecycle management Task 2.3). Log task receipt for audit trail.

2. **Execution Monitoring System:** Implement execution monitoring tracking Implementation agent work progress. Monitor agent process health (via Task 4.1 process tracking). Detect execution milestones (subtask completion, intermediate deliverables, test passes). Track execution metrics (time elapsed, steps completed, tests run). Detect execution anomalies (process hung, memory exhaustion, repeated errors). Implement execution timeout (task exceeds expected duration, investigate slowness). Support execution pause/resume for manual intervention. Monitor resource consumption (CPU, memory, disk I/O) preventing resource exhaustion. Emit execution events (milestone_reached, anomaly_detected, timeout_exceeded) for Manager coordination. Provide execution status queries for real-time monitoring.

3. **Memory Log Generation Validation:** Implement memory log validator ensuring agents generate properly formatted logs. Define memory log format requirements (per APM Memory_Log_Guide.md): markdown structure, required sections (Objective, Status, Progress, Blockers, Output), status markers (## Status: In Progress/Completed/Blocked), timestamped entries. Validate memory log updates ensuring format compliance. Check required sections present with expected content. Verify status markers use correct syntax. Ensure progress notes are descriptive and actionable. Validate output section contains deliverable descriptions. Detect malformed logs alerting agent to fix format. Provide validation feedback to agents improving log quality. Enforce completion criteria (completion marker must include deliverable summary, tests passing, quality gate results).

4. **Completion Reporting to Manager:** Implement completion reporting mechanism signaling task completion to Manager agent. Detect task completion from memory log completion marker (## Status: Completed). Validate completion criteria met (all subtasks complete, deliverables produced, tests passing, quality gates satisfied). Update memory log with completion summary (work done, deliverables produced, test results, metrics). Emit completion event via communication protocol (Task 3.1) to Manager agent. Update agent state to Waiting (ready for next task) via lifecycle management (Task 2.3). Record completion timestamp and metrics in database. Support completion acknowledgment from Manager (Manager confirms receipt, clears task assignment). Handle completion edge cases (partial completion, completion with warnings, completion pending approval).

5. **Error Escalation for Blockers:** Implement error escalation logic detecting blockers and escalating to Manager for user intervention. Detect blocker conditions: external dependency unavailable (API down, service unreachable), ambiguous requirements (unclear specification, conflicting instructions), test failures after multiple attempts (self-correction failed), resource constraints (insufficient permissions, quota exceeded), design decision needed (multiple valid approaches, user preference required). Generate blocker report including blocker description, attempted resolutions, context, recommended actions. Update memory log with blocker marker (## Status: Blocked, ## Blocker: [description]). Emit blocker event to Manager agent via communication protocol. Transition agent state to Blocked (via Task 2.3). Support blocker resolution (Manager provides resolution, agent resumes work, clears blocker status). Log all blockers and resolutions for analysis.

### Task 4.4 – Task Completion Detection │ Agent_Orchestration_Automation

- **Objective:** Implement task completion detection system polling memory files for completion markers, parsing memory logs to extract completion status, validating log completeness and format, and updating state database with accurate task completion information.
- **Output:** Completion detection module with memory file polling mechanism, completion marker parser, memory log format validator, and database state updater with comprehensive testing.
- **Guidance:** Depends on Task 4.3 Output. Integrate with memory file monitoring (Task 3.3) receiving memory log change events. Parse memory logs detecting completion markers (## Status: Completed). Validate completion ensuring deliverables documented, tests passed, quality gates satisfied. Update task state in database (Task 1.1) marking task completed. Handle partial completions and blocked states. Follow TDD testing detection with various memory log formats.

1. **Memory File Polling Implementation:** Implement memory file polling system monitoring task memory logs for completion updates. Subscribe to file change events from memory file watcher (Task 3.3) filtered by task memory log paths. Configure polling interval (1s for active tasks, 5s for queued tasks, 30s for completed tasks monitoring validation). Implement smart polling reducing overhead (poll frequently during active execution, reduce polling after completion detected). Track polling state per task (last poll time, last detected state, poll count). Handle polling errors gracefully (file not found yet, file locked, parse error) with retry logic. Support polling pause/resume for manual operations. Emit polling events (poll_started, state_detected, poll_error) for monitoring. Log polling activity for debugging state detection issues.

2. **Completion Detection Parser:** Implement completion marker parser extracting task status from memory logs. Define completion markers to detect: `## Status: Completed` (primary completion marker), `## Status: Blocked` (blocker detected), `## Status: Failed` (task failed permanently), deliverable documentation present (## Output: [deliverables]), test results documented (## Tests: Passed/Failed). Parse memory log markdown extracting status section content. Use regex patterns matching status markers with variation tolerance (case-insensitive, whitespace flexible). Extract completion metadata (completion timestamp from log, deliverables list, test results, quality gate outcomes). Handle ambiguous status (multiple status markers, conflicting indicators) defaulting to most recent marker. Return structured completion result (status enum, timestamp, metadata, confidence score).

3. **Memory Log Format Validation:** Implement memory log validator checking completion log quality. Validate required sections present for completion: Objective (task goal documented), Status (completion marker present), Progress (work history documented), Output (deliverables described), Tests (test results included), Quality Gates (constitutional validation results). Check completion marker syntax correct (exact format per Memory_Log_Guide.md). Verify deliverables documented with descriptions matching Output field from Task Assignment Prompt. Validate test results show passing tests with coverage metrics. Check quality gate results show constitutional compliance (TDD, conventional commits, security checks). Generate validation report (sections present, format correct, content complete, warnings/errors). Support validation strictness levels (strict requires all fields, lenient allows missing optional sections).

4. **Database State Updates:** Implement state updater persisting completion status to database. Update task record in tasks table (from Task 1.1 schema) with completion data: status=Completed, completed_at=timestamp, deliverables=JSON, test_results=JSON, validation_results=JSON. Update agent state in agent_states table marking agent Waiting (ready for next task). Record state transition in agent_state_transitions audit table. Implement atomic updates using database transactions ensuring consistency. Handle update conflicts (concurrent updates from multiple sources) using optimistic locking or last-write-wins strategy. Emit database update events for coordination. Support bulk updates (mark multiple tasks complete in single transaction). Validate database state after update ensuring consistency with memory log status. Log all state updates for audit trail.

## Phase 5: Constitution & Quality Gates

### Task 5.1 – spec-kit Checklist Integration │ Agent_Constitution

- **Objective:** Integrate spec-kit constitution checklist validation system parsing checklist markdown files, validating checklist items against task execution, integrating checkpoints at task/commit/phase/handover boundaries, and reporting validation results with failure handling.
- **Output:** spec-kit integration module with checklist markdown parser, validation logic engine, checkpoint integration system, and comprehensive validation reporting with failure escalation.
- **Guidance:** Parse spec-kit checklist format from Context Synthesis spec-kit repository patterns. Checklists are "unit tests for requirements" validating requirement quality, not implementation. Integrate checkpoints at key moments: task completion, pre-commit, phase completion, pre-handover. Each checkpoint validates relevant checklist items. Report validation results (pass/fail/warning). Escalate failures blocking progression until resolved. Follow TDD testing validation scenarios.

1. **Checklist Parser Implementation:** Implement spec-kit checklist markdown parser extracting validation items from checklist files. Parse checklist format: `- [ ] CHK001 - [Item description] [Dimension]` where Dimension is Completeness/Clarity/Consistency/etc. Extract checklist metadata (title, purpose, created date, category). Parse checklist items into structured format (ID, description, category, dimension, checked status). Support checklist sections organizing items by validation category (Requirement Completeness, Requirement Clarity, etc.). Validate checklist syntax warning on malformed items. Handle checklist references (links to spec sections, gap markers). Return parsed checklist as typed data structure with all items and metadata. Support checklist caching for performance.

2. **Validation Logic Engine:** Implement validation engine checking task execution against checklist items. For each checklist item, determine validation method: automated check (parseable validation rule), manual check (requires user confirmation), hybrid check (automated with manual override). Implement validation rules: completeness checks (all required artifacts present), clarity checks (specs unambiguous, measurable), consistency checks (no conflicting requirements), coverage checks (all scenarios addressed). Execute validation returning item status (pass, fail, warning, skip). Collect validation results across all checklist items. Generate validation summary (total items, passed, failed, warnings, skipped). Support validation contexts (task-level, commit-level, phase-level, handover-level) with different checklist subsets.

3. **Checkpoint Integration System:** Integrate checkpoints at key validation moments. Define checkpoint types: task_end (validate before marking task complete), pre_commit (validate before git commit), phase_end (validate before moving to next phase), pre_handover (validate before agent handover). Register checkpoint handlers subscribing to relevant events (task completion event, commit event, phase completion event, handover trigger event). Execute appropriate checklist validation at each checkpoint. Configure checkpoint behavior (blocking vs warning, strict vs lenient validation). Track checkpoint execution history (which checkpoints run, when, results). Support checkpoint skip for emergency situations with justification required and audit logging. Emit checkpoint events (checkpoint_started, checkpoint_completed, checkpoint_failed) for monitoring.

4. **Validation Reporting and Failure Handling:** Implement comprehensive validation reporting. Generate validation reports including: checkpoint type and timestamp, checklist items validated (passed/failed/skipped), failure details (which items failed, why, evidence), warnings (non-blocking issues), recommendations (how to fix failures). Format reports as markdown for readability and as JSON for programmatic consumption. Display reports to user with actionable guidance. For validation failures: block progression (prevent task completion, abort commit, stop phase transition), notify user with report, suggest fixes based on failure patterns, support manual override with justification, log all failures and overrides for audit. Implement failure retry (fix issues, re-run validation). Track validation metrics (validation success rate, common failure patterns, time to fix).

### Task 5.2 – Pre-commit Hook Implementation │ Agent_Constitution

- **Objective:** Create pre-commit git hook system enforcing security checks, secrets detection, commit message validation for conventional commits format, and emergency bypass mechanism with comprehensive audit trail logging.
- **Output:** Pre-commit hook installation script, security vulnerability scanners, secrets detection engine, conventional commits validator, emergency bypass logic with audit logging, and complete test suite.
- **Guidance:** Install git pre-commit hooks preventing commits violating constitutional principles. Implement security checks scanning for common vulnerabilities (hardcoded credentials, unsafe dependencies, SQL injection patterns). Use secrets detection patterns identifying API keys, tokens, passwords in code. Validate commit messages following conventional commits format (feat/fix/chore/docs: description). Support hook bypass for emergencies with justification required. Log all hook executions and bypass events. Follow TDD testing hook scenarios.

1. **Hook Installation Script:** Implement pre-commit hook installation integrated with apm-auto initialization. Create hook installation command `apm-auto hooks install` copying hook script to .git/hooks/pre-commit and making it executable. Generate hook script invoking apm-auto validation logic (call `apm-auto validate commit` internally). Support hook configuration (enable/disable specific checks, configure severity thresholds, set bypass password). Detect existing hooks preserving custom hooks via hook chaining (call existing hook before apm-auto hook). Implement hook uninstall command removing apm-auto hooks cleanly. Validate hook installation ensuring hook executable and properly configured. Support per-repository and global git hook installation.

2. **Security Vulnerability Checks:** Implement security scanners detecting common vulnerabilities in code changes. Scan for hardcoded credentials (regex patterns matching API keys, passwords, access tokens, database credentials). Detect unsafe API usage (eval(), exec(), dangerous RegEx, SQL string concatenation). Check dependency security (flag outdated packages with known CVEs, suggest updates). Scan for injection vulnerabilities (SQL injection patterns, XSS vulnerabilities, command injection risks). Validate file permissions on sensitive files (private keys, config files must have restrictive permissions). Use OWASP Top 10 patterns as validation baseline. Generate security report listing detected vulnerabilities with severity levels (critical, high, medium, low). Block commits containing critical vulnerabilities. Warn on medium/low vulnerabilities allowing commit with acknowledgment.

3. **Secrets Detection Engine:** Implement secrets detector scanning code changes for exposed secrets. Define secret patterns: API keys (AWS, GCP, Azure, GitHub, etc.), OAuth tokens, database passwords, private keys (SSH, PGP, SSL), encryption keys, webhook URLs with tokens. Use regex patterns and entropy analysis detecting high-entropy strings likely to be secrets. Scan commit diff (only check added/modified lines, ignore removed lines). Check against known secret databases (GitHub secret scanning patterns). Generate secrets report listing detected secrets with file path, line number, secret type, confidence score. Block commits containing high-confidence secrets. Provide guidance on secret management (use environment variables, secret managers, .gitignore sensitive files). Support secret allowlist for false positives (hash-based exclusion preventing pattern abuse).

4. **Conventional Commits Validation:** Implement conventional commits format validator ensuring commit messages follow standard format. Parse commit message extracting components: type (feat/fix/docs/style/refactor/test/chore), scope (optional), subject (description), body (optional), footer (optional). Validate type is recognized conventional type. Check subject format (imperative mood, lowercase, no period, <50 chars). Validate body format (wrap at 72 chars, blank line after subject). Check footer for breaking changes (BREAKING CHANGE:) and issue references (#123). Generate validation report showing format violations. Block commits with invalid messages providing examples of correct format. Support custom commit types via configuration (allow additional types beyond conventional set). Integrate with semantic versioning (type determines version bump).

5. **Emergency Bypass and Audit Logging:** Implement emergency bypass mechanism for urgent commits. Support bypass flag `git commit --no-verify` (standard git bypass). Add apm-auto bypass `APM_AUTO_BYPASS=reason git commit` requiring justification. Prompt for bypass reason if not provided (interactive mode). Log all bypass events to audit trail including: timestamp, committer, bypass reason, which checks bypassed, commit hash. Store bypass log in `.apm-auto/audit/bypass.log` for review. Implement bypass approval for critical repos (require second person approval for bypass). Generate bypass reports showing bypass frequency, common reasons, patterns. Alert on excessive bypass usage (>10% of commits bypassed). Support bypass review workflow (reviewers check bypassed commits post-commit).

### Task 5.3 – Quality Gate Enforcement │ Agent_Constitution

- **Objective:** Define and enforce quality gates at critical validation points (task end, pre-commit, phase end, pre-handover) with blocking logic preventing progression on failures, bypass mechanisms requiring justification, and comprehensive audit logging for all gate events.
- **Output:** Quality gate framework with gate definitions at validation points, enforcement logic blocking progression on failures, bypass mechanism with justification requirements, and audit logging system.
- **Guidance:** Depends on Task 5.1 Output and Task 5.2 Output. Quality gates are checkpoints enforcing constitutional principles before progression. Define gates at key moments: task completion (deliverables complete, tests pass, spec-kit checklist validated), pre-commit (security checks pass, no secrets, conventional commits), phase completion (all tasks complete, integration tests pass, documentation updated), pre-handover (context documented, state persisted, clean transition possible). Implement blocking logic preventing progression until gates pass. Support emergency bypass with justification. Log all gate events for audit.

- **Quality Gate Definitions:** Define quality gates at validation points with specific pass criteria. Task End Gate: deliverables documented in memory log, all tests passing (100% pass rate per Context Synthesis), code coverage ≥80% (per Context Synthesis), spec-kit checklist validated (all CHK items addressed), no unresolved blockers. Pre-Commit Gate: security checks pass (no critical vulnerabilities), secrets detection clean (no exposed secrets), conventional commits format valid, pre-commit hooks execute successfully. Phase End Gate: all phase tasks completed, integration tests pass, phase documentation updated (README, CHANGELOG), phase demo completed (agile delivery requirement). Pre-Handover Gate: agent context documented, state persisted to checkpoint, memory logs complete, handover context prepared. Document gate criteria and rationale for each gate type.

- **Enforcement Logic Implementation:** Implement gate enforcement blocking progression until criteria met. Register gate handlers subscribing to progression events (task_completing, commit_starting, phase_completing, handover_triggering). Execute gate validation when progression event fires. Evaluate all gate criteria returning aggregate result (pass/fail, specific failures). For gate failures: block progression (prevent task completion, abort commit, stop phase transition, cancel handover), notify user with failure report (which criteria failed, evidence, how to fix), log enforcement event (gate type, result, failures, timestamp). For gate success: allow progression, log success event, proceed with next step. Implement enforcement strictness levels (strict blocks always, lenient allows warnings, audit logs only). Support gate dependencies (some gates require other gates passing first).

- **Bypass Mechanism with Justification:** Implement quality gate bypass for exceptional circumstances. Define bypass conditions: emergency situations (critical bug fix, production incident), gate malfunction (false positive, validation bug), process exception (approved deviation from standard process). Require bypass justification via prompt: describe reason, assess risk, document mitigation, specify approval. Validate bypass request ensuring justification adequate (minimum character count, required fields present). Approve bypass automatically for authorized users or escalate for approval workflow. Log bypass events with full context (gate bypassed, justification, risk assessment, approver, timestamp). Track bypass metrics (bypass frequency per gate, common reasons, impact). Generate bypass reports for process improvement. Implement bypass expiry (bypass valid for single event only, not permanent exemption).

- **Audit Logging System:** Implement comprehensive audit logging for all quality gate events. Log gate execution events: gate triggered (type, timestamp, context), gate evaluation (criteria checked, results, duration), gate result (pass/fail, specific failures), progression decision (blocked/allowed/bypassed). Log bypass events: bypass requested (reason, risk), bypass approved/denied (approver, timestamp), bypass executed (gate bypassed, context). Store logs in `.apm-auto/audit/quality-gates.log` with structured format (JSON lines). Implement log rotation preventing unbounded growth (daily rotation, keep last 30 days). Support log querying (search by gate type, result, date range). Generate audit reports (gate pass rates, failure patterns, bypass statistics). Integrate logs with monitoring systems for alerting on gate failures or bypass abuse.

### Task 5.4 – Constitutional Validation Framework │ Agent_Constitution

- **Objective:** Implement constitution validation framework parsing constitution from spec-kit repository patterns, validating task execution against constitutional principles, enforcing compliance checking at defined checkpoints, and generating compliance reports for audit trail.
- **Output:** Constitution parser extracting principles from spec-kit, principle validation engine checking execution compliance, checkpoint enforcement integration, and compliance reporting system with audit trail.
- **Guidance:** Parse constitution document from spec-kit repository reviewed during Context Synthesis. Constitution defines non-negotiable principles (TDD, conventional commits, security checks, quality gates, documentation standards). Validate task execution against principles ensuring compliance. Enforce validation at constitutional checkpoints (task completion, commit, phase end, handover). Generate compliance reports showing adherence to principles. Log all validation events for audit. Follow TDD testing validation scenarios.

1. **Constitution Parser:** Implement constitution document parser extracting principles from spec-kit constitution.md format. Parse constitution structure: preamble (governance overview), principles sections (numbered principles with names, descriptions, rationale), governance section (amendment procedure, versioning). Extract principle definitions: principle ID, name, description (what must be done), rationale (why it matters), validation criteria (how to check compliance), enforcement level (mandatory/recommended). Parse principle metadata (last amended date, version, status). Support constitution versioning (track changes, maintain history). Validate constitution syntax ensuring well-formed document. Return parsed constitution as structured data (principles array, governance rules, metadata). Cache parsed constitution for performance.

2. **Principle Validation Engine:** Implement validation engine checking task execution against constitutional principles. For each principle, determine validation approach: automated validation (executable checks), semi-automated validation (checks with manual review), manual validation (human judgment required). Implement principle-specific validators: TDD Principle (tests exist before code, tests pass, coverage ≥80%), Conventional Commits Principle (commit messages follow format), Security Checks Principle (no vulnerabilities, no secrets), Quality Gates Principle (gates enforced, not bypassed), Documentation Standards Principle (docs updated, complete, accurate). Execute validators collecting compliance evidence (test reports, commit logs, scan results). Generate validation results per principle (compliant/non-compliant, evidence, confidence score). Support principle dependencies (some principles build on others).

3. **Compliance Checking at Checkpoints:** Integrate constitutional compliance checking with quality gate checkpoints (Task 5.3). Define constitutional checkpoints: task completion (validate TDD, documentation principles), commit time (validate conventional commits, security principles), phase completion (validate all principles for phase scope), handover (validate state documentation, transition principles). Execute principle validation at each checkpoint. Collect validation results across all relevant principles. Determine checkpoint pass/fail based on principle compliance (all mandatory principles must comply). For compliance failures: block checkpoint, report non-compliant principles, suggest remediation. For compliance success: allow checkpoint progression, log compliance. Track compliance metrics (principles compliance rate, common violations, compliance trends over time).

4. **Compliance Reporting and Audit:** Generate comprehensive compliance reports documenting constitutional adherence. Report structure: executive summary (overall compliance status, principle adherence percentage), principle breakdown (each principle with compliance status, evidence, violations), violations section (non-compliant items, severity, impact, remediation), trends (compliance over time, improvement areas), recommendations (how to improve compliance). Format reports as markdown for readability and JSON for programmatic analysis. Store compliance reports in `.apm-auto/audit/compliance/` directory timestamped. Implement compliance dashboard showing real-time compliance status. Generate audit trail logging all compliance checks (checkpoint, principles validated, results, timestamp). Support compliance queries (find non-compliant tasks, analyze violation patterns). Create compliance alerts for significant violations or compliance degradation.

## Phase 6: Testing Infrastructure

### Task 6.1 – Mock Agent Framework │ Agent_Testing

- **Objective:** Design and implement comprehensive mock agent framework simulating Claude Code agent responses, enabling TDD without requiring actual Anthropic API calls, with predictable test scenarios, state mocking, and response templating for reliable automated testing.
- **Output:** Mock agent architecture with Claude Code CLI simulator, state mocking utilities for database and beads integration, response template system for predictable test scenarios, and validation utilities verifying mock behavior correctness.
- **Guidance:** Create mock framework supporting unit tests without real Claude Code or Anthropic API. Mock Claude CLI execution returning canned responses based on test scenarios. Mock database operations using in-memory database. Mock beads CLI commands returning predictable issue data. Implement response templates for common scenarios (successful task execution, task failure, blocker encountered, handover triggered). Support mock configuration per test (set expected inputs, define mock outputs). Follow TDD—use mocks to test all modules before integration testing.

1. **Mock Agent Architecture Design:** Design mock agent system architecture simulating Claude Code agent lifecycle. Define mock agent interface matching real agent interface (spawn, execute, terminate, query state). Implement mock agent factory creating mock instances with configurable behavior. Support mock agent modes: success mode (always completes successfully), failure mode (fails with specified error), blocker mode (encounters blocker requiring intervention), timeout mode (simulates hung agent). Configure mock agent parameters: execution delay (simulate processing time), response template (predefined agent output), state transitions (sequence of states agent passes through). Implement mock agent verification asserting mock was called with expected inputs. Support multiple concurrent mock agents for parallelization tests.

2. **Claude Code CLI Simulator:** Implement Claude CLI simulator mocking `claude 'prompt'` command execution. Mock child_process.spawn returning mock process object. Configure mock process behavior: stdout stream (emit canned responses), stderr stream (emit error messages or empty), exit code (0 for success, non-zero for error), execution delay (simulate agent processing time). Implement prompt inspection recording prompts sent to mocked CLI for verification. Support response templating injecting test data into responses. Mock process events (spawn, exit, error) with configurable timing. Validate spawned processes cleaned up properly (no zombie processes in mock). Test with various failure scenarios (CLI not found, spawn timeout, invalid prompt).

3. **State Mocking for Database and Beads:** Implement state mocking utilities for database and beads integrations. Database Mocking: use in-memory SQLite database for tests (initialize schema, clean between tests), pre-populate test data (agents, tasks, states), mock database errors for error handling tests (connection failures, constraint violations), verify database state after operations. Beads Mocking: mock beads CLI commands returning canned JSON responses, configure mock beads issue data (ready tasks, blockers, dependencies), simulate beads query delays, validate beads commands called with correct arguments. Export mock factories creating pre-configured mocks for common scenarios. Support mock reset clearing state between tests.

4. **Response Templating System:** Create response template system generating predictable mock agent responses. Define template types: task_success (agent completes task successfully with deliverables), task_failure (agent fails with error message), task_blocker (agent encounters blocker with description), partial_completion (agent completes some but not all subtasks), handover_request (agent requests handover due to context limit). Implement template variables: {{TASK_ID}}, {{DELIVERABLES}}, {{ERROR_MESSAGE}}, {{BLOCKER_REASON}}, {{PROGRESS_PERCENTAGE}}. Store templates in test fixtures directory. Load templates by scenario name returning populated response string. Support template composition (base response + scenario-specific additions). Validate rendered templates ensuring all variables populated.

5. **Mock Validation Utilities:** Implement validation utilities verifying mock behavior in tests. Assertion helpers: assertMockCalled (verify mock invoked), assertMockCalledWith (verify called with specific args), assertMockCallCount (verify call frequency), assertMockNotCalled (verify mock not invoked). Mock inspection utilities: getMockCalls (retrieve all calls to mock), getMockCallArgs (get arguments from specific call), getMockReturnValues (get all return values). Mock verification: verifyMockExpectations (assert all expected calls occurred), resetMockState (clear mock history). Support mock call ordering assertions (verify calls in specific sequence). Implement mock debugging utilities printing mock state for troubleshooting test failures.

### Task 6.2 – Unit Test Suite │ Agent_Testing

- **Objective:** Organize comprehensive unit test suite following TDD best practices, write component tests for all modules using mocks from Task 6.1, implement coverage tracking enforcing 80% minimum, and add pass rate validation ensuring 100% success requirement with no skipped tests.
- **Output:** Organized test suite structure, component tests for all modules achieving 80%+ coverage, coverage tracking and reporting system, and pass rate enforcement blocking deployment on test failures.
- **Guidance:** Depends on Task 6.1 Output. Organize tests by module mirroring src/ structure. Write tests before implementation (TDD). Use mocks for all external dependencies (database, beads, Claude CLI, file system). Implement test utilities (setup, teardown, fixtures). Configure Vitest for coverage tracking (istanbul or c8). Enforce 80% coverage threshold failing build if not met. Require 100% pass rate—no test skips, no test modifications to force passes. Follow "fix code not tests" philosophy from Context Synthesis.

1. **Test Suite Organization:** Organize test suite structure following best practices. Mirror source structure: `src/module.ts` → `tests/unit/module.test.ts`. Group related tests using describe blocks (describe('ModuleName', ...)). Organize tests by functionality within modules (describe('MethodName', ...)). Implement test utilities directory (tests/utils/) with common helpers (createMockDatabase, mockBeadsResponse, etc.). Create test fixtures directory (tests/fixtures/) with sample data (Implementation Plans, memory logs, config files). Setup global test configuration (vitest.config.ts) with coverage settings, timeout values, setup files. Implement test naming convention (it('should [expected behavior] when [condition]', ...)). Use consistent test structure (Arrange-Act-Assert pattern).

2. **Component Test Implementation:** Write comprehensive component tests for all modules using mocks. Database Layer Tests: test connection management (open, close, pooling), schema creation (tables, indexes, constraints), CRUD operations (insert, select, update, delete), transaction handling (commit, rollback), error scenarios (connection failure, constraint violation). State Machine Tests: test state transitions (valid transitions allowed, invalid rejected), persistence (state saved to DB, loaded correctly), event emission (events fired on transitions), recovery (crashed agent detection, restart logic). CLI Tests: test command parsing (valid commands, invalid syntax), option handling (required options, defaults), help text (displayed correctly), error messages (actionable, clear). Use mocks for all external dependencies. Test both success paths and error paths. Achieve 80%+ coverage per module.

3. **Coverage Tracking and Reporting:** Implement test coverage tracking using Vitest coverage features (c8 or istanbul). Configure coverage thresholds in vitest.config.ts: global 80%, per-file 70%, functions 80%, lines 80%, branches 75%. Enable coverage reporters: text (console output), html (detailed report), json (programmatic analysis), lcov (CI integration). Generate coverage reports in coverage/ directory. Implement coverage enforcement failing test run if thresholds not met. Create coverage dashboard (HTML report) showing module-by-module coverage. Track coverage trends over time (store historical coverage data). Identify low-coverage areas needing additional tests. Exclude intentional uncovered code (error paths that can't be reached, defensive code) with explicit annotations and justification comments.

4. **Pass Rate Validation:** Implement 100% pass rate enforcement per Context Synthesis requirement. Configure test framework rejecting test skips (it.skip, it.todo throw errors). Disable test modification shortcuts (changing assertions to make tests pass, removing failing tests). Implement test result validation: parse test output, count total tests, count passed tests, verify pass rate = 100%, fail build if any test fails. Create test failure report including failed test names, error messages, stack traces, failure context. Require all tests green before allowing commits (via pre-commit hook from Task 5.2). Support test retry for flaky tests (retry max 2 times, mark as flaky if passes on retry). Track test reliability metrics (flaky test rate, failure frequency). Follow "fix code not tests" principle: failing test indicates code bug, not test bug.

### Task 6.3 – Integration Test Infrastructure │ Agent_Testing

- **Objective:** Configure integration testing infrastructure with real Anthropic API connectivity, create integration tests executing actual agent spawning and coordination, implement test environment setup with proper configuration, ensure test isolation preventing cross-test interference, and create teardown procedures for thorough cleanup.
- **Output:** Integration test configuration with Anthropic API integration, real agent integration tests, test environment setup scripts, test isolation mechanisms, and cleanup procedures ensuring clean test state.
- **Guidance:** Depends on Task 6.2 Output. Integration tests use real Anthropic Claude Code CLI and API (requires API key in env). Test full automation workflows (spawn agent, execute task, detect completion). Setup test environment (create temp .apm/ directories, initialize test database, load test Implementation Plans). Isolate tests (separate temp directories per test, clean database between tests). Teardown thoroughly (terminate spawned agents, clean temp files, reset database). Run integration tests in CI but skip locally if API key unavailable. Track API usage and costs.

1. **Anthropic API Integration Configuration:** Configure integration test environment for real Anthropic API usage. Load API key from environment variable (ANTHROPIC_API_KEY) required for integration tests. Validate API key present before running integration tests (skip with warning if missing). Configure test timeout (5 minutes per integration test allowing for API latency). Implement API rate limiting respecting Anthropic quotas (max N requests per minute). Setup API retry logic for transient failures (network errors, rate limits). Configure test API usage tracking recording token consumption and API costs per test. Implement API mock fallback mode allowing integration test development without API key (using sophisticated mocks mimicking API behavior). Document API key setup requirements for developers and CI.

2. **Real Agent Integration Tests:** Write integration tests executing real Claude Code CLI and Anthropic API calls. Test Complete Task Workflow: spawn Implementation agent with Task Assignment Prompt, monitor memory log for progress updates, wait for task completion (timeout 5 min), validate task deliverables created, verify agent terminated cleanly. Test Manager Orchestration: spawn Manager agent coordinating multiple Implementation agents, verify task assignment prompts generated correctly, validate dependency resolution working, confirm cross-agent handoffs successful. Test Error Recovery: trigger agent failure (inject blocker in prompt), verify error detection and escalation, test automatic restart logic, validate recovery from checkpoint. Test Handover Flow: trigger context limit handover, verify old agent terminates, new agent spawns with context, work continues seamlessly. Use real .apm/ structure, real Implementation Plans, real database. Validate end-to-end automation.

3. **Test Environment Setup:** Implement test environment initialization for integration tests. Create temporary .apm/ directory structure per test (Memory/, guides/, Implementation_Plan.md). Initialize test database (SQLite in-memory or temp file) with schema from migrations. Load test Implementation Plan into .apm/ directory (use fixture plans for predictable tests). Initialize beads database with test issue data (if integration with beads required). Setup test configuration (autonomy level, resource limits, test-specific overrides). Configure logging (verbose logging for debugging, captured in test output). Export environment variables required by tests (API keys, database path, config path). Implement test isolation ensuring tests don't interfere (separate temp dirs, fresh database, no shared state). Create test context object providing access to environment (temp paths, database connection, test data).

4. **Test Isolation Mechanisms:** Implement test isolation preventing cross-test contamination. Directory Isolation: create unique temp directory per test (use test name + timestamp), all file operations scoped to test directory, cleanup directory after test. Database Isolation: create new in-memory database per test OR use single database with transaction rollback (each test in transaction, rollback after test), reset sequences between tests, clear all tables before test. Process Isolation: track spawned processes per test, terminate all processes in teardown, ensure no lingering child processes. State Isolation: reset global state between tests (clear singletons, reset module state), mock time for deterministic tests, isolate network requests (no external calls except deliberate API tests). Verify isolation with canary tests (run test twice, verify results identical).

5. **Cleanup and Teardown Procedures:** Implement thorough cleanup ensuring no test artifacts remain. Process Cleanup: enumerate all child processes spawned during test, send SIGTERM to each process, wait for graceful termination (5s timeout), send SIGKILL if still running, verify no zombie processes remain. File Cleanup: delete temporary .apm/ directory and all contents, remove test database files, clean log files, delete any temp config files. State Cleanup: close all database connections, clear event listeners, cancel pending timers/promises, reset mocked modules. Memory Cleanup: force garbage collection in test teardown (if needed), detect memory leaks (growing memory usage across tests). Verify cleanup with post-test assertions (temp directories deleted, no lingering processes, database closed). Log cleanup failures for debugging.

### Task 6.4 – CI/CD Pipeline with GitHub Actions │ Agent_Testing

- **Objective:** Create GitHub Actions workflow configuration automating CI/CD pipeline with separate staging and production environments, configure secrets and SSH keys for remote deployment, create deployment scripts for both environments, and integrate Coderabbit.ai for automated PR code review.
- **Output:** GitHub Actions workflow files (.github/workflows/), environment configurations for staging and production, SSH key management for remote deployment, deployment automation scripts, and Coderabbit.ai integration.
- **Guidance:** Depends on Task 6.3 Output. Create CI/CD workflow running on push and PR. Execute tests (unit + integration if API key available), enforce coverage thresholds, run security checks (from Task 5.2), build artifacts, deploy to staging on main branch, deploy to production on release tags. Configure GitHub environments (staging, production) with approval gates. Setup SSH keys for remote server deployment. Integrate Coderabbit.ai for PR review automation. Follow Context Synthesis requirements: staging/production separation, SSH deployment, multi-tenant environment considerations.

1. **GitHub Actions Workflow Configuration:** Create GitHub Actions workflow files in .github/workflows/. CI Workflow (ci.yml): trigger on push to all branches and PRs, checkout code, setup Node.js environment, install dependencies (npm ci), run linters (eslint, prettier), run unit tests with coverage, enforce 80% coverage threshold (fail if not met), run security checks (secrets detection, vulnerability scan), build TypeScript (tsc), upload test results and coverage artifacts. Deploy Staging Workflow (deploy-staging.yml): trigger on push to main branch, run CI workflow first (must pass), build deployment package, deploy to staging server via SSH, run smoke tests on staging, notify on success/failure. Deploy Production Workflow (deploy-production.yml): trigger on release tag (v*), require manual approval, run full test suite, deploy to production server via SSH, run health checks, notify on deployment.

2. **Environment Configuration:** Configure GitHub Environments for staging and production with secrets and protection rules. Staging Environment: secrets (STAGING_SSH_KEY, STAGING_HOST, STAGING_USER, STAGING_PATH, ANTHROPIC_API_KEY), protection rules (none, auto-deploy on main branch), environment URL (https://staging.apm-auto.example.com). Production Environment: secrets (PRODUCTION_SSH_KEY, PRODUCTION_HOST, PRODUCTION_USER, PRODUCTION_PATH), protection rules (required reviewers: 1, manual approval required, restrict to release tags), environment URL (https://apm-auto.example.com). Setup environment variables (NODE_ENV=staging/production, LOG_LEVEL=info/error). Document secret setup requirements. Implement secret rotation procedures. Validate all required secrets present before deployment.

3. **SSH Key Management and Deployment:** Setup SSH key-based authentication for remote server deployment per Context Synthesis multi-tenant environment. Generate deployment SSH keys (ed25519) per environment (staging key, production key). Store private keys in GitHub Secrets (STAGING_SSH_KEY, PRODUCTION_SSH_KEY). Add public keys to server authorized_keys for deployment user. Implement SSH connection testing in workflow validating key works before deployment. Configure SSH options: StrictHostKeyChecking=accept-new, UserKnownHostsFile=/dev/null (CI environment), connection timeout=30s. Handle multi-tenant considerations: check port availability before deployment (avoid port conflicts per Context Synthesis), deploy to unique directory per environment, update symlinks for zero-downtime deployment. Implement rollback procedure restoring previous deployment on failure.

4. **Deployment Automation Scripts:** Create deployment scripts automating staging and production deployment. Deployment Script (scripts/deploy.sh): accept parameters (environment, version, host, user, ssh-key-path), connect to remote server via SSH, create deployment directory (releases/YYYY-MM-DD-HH-MM-SS/), upload deployment package (rsync or scp), install dependencies (npm ci --production), run database migrations (apm-auto migrate up), update symlink (current → new release), restart service (systemd or PM2), run health checks (curl health endpoint), keep last N releases for rollback. Pre-deployment Checks: verify disk space available, check service health before deployment, backup current version. Post-deployment: verify service running, check logs for errors, run smoke tests. Rollback script reversing deployment if health checks fail.

5. **Coderabbit.ai Integration:** Integrate Coderabbit.ai for automated PR code review per Context Synthesis preference. Install Coderabbit GitHub App granting repository access. Configure Coderabbit in .coderabbit.yml: review rules (check for bugs, performance issues, security vulnerabilities, code style), language settings (TypeScript, Node.js best practices), exclusions (ignore test files, generated code), auto-review on PR open/update. Customize review focus: prioritize logic errors over linting nitpicks per Context Synthesis ("read every comment for bugs, ignore nitpicks"). Configure review thresholds (auto-approve if no issues, request changes if critical issues). Setup review notifications (comment on PR with findings). Document Coderabbit usage for team: "review all Coderabbit comments for logic errors, acknowledge style suggestions but not required to fix". Implement Coderabbit feedback loop improving review accuracy over time.

## Phase 7: Session Management & Recovery

### Task 7.1 – Session State Persistence │ Agent_Orchestration_Session

- **Objective:** Implement session state persistence system serializing complete session state to checkpoints, create checkpoint triggers for manual, automatic, and pre-pause scenarios, add checkpoint restoration logic enabling session recovery, and validate checkpoint integrity ensuring reliable state recovery.
- **Output:** State serialization module converting session state to JSON, checkpoint creation system with multiple triggers, checkpoint restoration logic, integrity validation utilities, and comprehensive testing.
- **Guidance:** Depends on Task 1.1 Output by Agent_Orchestration_Foundation. Persist session state enabling resume after interruption. Serialize to JSON including: active agents (IDs, states, task assignments), task queue (pending/in-progress tasks), database snapshot, configuration. Create checkpoints on: manual command (`apm-auto checkpoint create`), automatic timer (every 30 min), pre-pause (before `apm-auto stop`), handover (before agent transition). Store checkpoints in .apm-auto/checkpoints/ directory. Validate integrity with checksums. Follow TDD testing serialization and restoration.

1. **State Serialization Implementation:** Implement session state serializer converting runtime state to persistent JSON format. Define serialization schema: SessionCheckpoint { version, timestamp, agents: [{ id, type, state, taskId, processId }], tasks: [{ id, status, assignedAgent, dependencies, progress }], queue: { pending: [], inProgress: [] }, config: { autonomyLevel, resourceLimits }, database: { snapshot or migration version }, metadata: { reason, triggeredBy } }. Implement serializer walking object graph collecting state. Handle special types (dates→ISO strings, buffers→base64). Exclude non-serializable data (function references, circular refs, large blobs). Compress serialized JSON (gzip) reducing checkpoint size. Add checksum (SHA-256) for integrity validation. Return checkpoint object ready for persistence.

2. **Checkpoint Creation Triggers:** Implement checkpoint triggers creating checkpoints at key moments. Manual Trigger: `apm-auto checkpoint create [reason]` command, prompt for checkpoint reason if not provided, create immediate checkpoint, return checkpoint ID. Automatic Timer Trigger: setInterval creating checkpoint every 30 minutes (configurable), check if session active before checkpoint, skip if no state changes since last checkpoint, log automatic checkpoints. Pre-Pause Trigger: hook into `apm-auto stop` command, create checkpoint before terminating agents, ensure checkpoint complete before shutdown, validate checkpoint created successfully. Handover Trigger: detect agent handover events (from Task 4.2), create checkpoint capturing pre-handover state, include handover context in checkpoint metadata. Track checkpoint creation metrics (frequency, size, duration).

3. **Checkpoint Restoration Logic:** Implement checkpoint restoration enabling session resume. Load checkpoint by ID or "latest" from .apm-auto/checkpoints/ directory. Deserialize JSON parsing checkpoint schema. Validate checkpoint format ensuring version compatible with current apm-auto version. Restore state components: reconstruct agent states (respawn agents if needed, restore task assignments), rebuild task queue (pending and in-progress tasks), restore configuration (autonomy level, resource limits), restore database state (via migrations or snapshot). Implement partial restoration (restore specific components, skip corrupted sections). Validate restored state consistency (all agent references valid, task dependencies satisfied). Log restoration events (checkpoint used, components restored, any skipped).

4. **Checkpoint Integrity Validation:** Implement checkpoint validation ensuring checkpoint data integrity and recoverability. Checksum Validation: compute SHA-256 hash of checkpoint content, compare against stored checksum, reject checkpoint if mismatch (corrupted data). Schema Validation: parse checkpoint JSON against schema, verify all required fields present, validate field types and constraints, check version compatibility. Consistency Validation: verify agent references valid (agents exist in checkpoint), validate task dependencies (all dependency tasks in checkpoint), check configuration valid (autonomy level allowed, resource limits reasonable). Corruption Detection: detect truncated files (incomplete JSON), identify malformed data (invalid UTF-8, corrupted compression), find missing components (database snapshot absent). Report validation results (valid/invalid, specific issues, repair suggestions). Implement checkpoint repair attempting to fix minor issues (missing non-critical fields, recompute checksums).

## Phase 8: Git Worktree Integration

### Task 8.1 – Worktree Creation and Management │ Agent_Git

- **Objective:** Implement git worktree creation and management enabling parallel agent execution in isolated branches, create worktree based on Manager agent decisions, add agent-to-worktree mapping in state database, implement cleanup procedures for completed worktrees, and validate worktree consistency.
- **Output:** Worktree management module with creation logic, branch management for isolation, database mapping system, cleanup automation, and consistency validation.
- **Guidance:** Git worktrees enable multiple working directories from single repository allowing parallel agent execution per Context Synthesis v2 requirement. Create worktrees when Manager determines domain separation warrants parallel work. Map agents to worktrees in database. Track worktree status (active, merged, abandoned). Cleanup completed worktrees after merge. Follow TDD with mocked git commands for unit tests, real git operations for integration tests.

1. **Worktree Creation Logic:** Implement worktree creation executing git commands. Detect when Manager agent requests worktree (domain separation needed, parallel execution beneficial). Generate unique worktree directory name (worktrees/agent-<agent-id>-<timestamp>). Create new branch for worktree (git branch <branch-name> <base-ref>). Create worktree (git worktree add <path> <branch-name>). Configure worktree git settings (user.name, user.email, remote). Initialize .apm/ directory in worktree (copy guides, create Memory/ structure). Update database with worktree record (path, branch, agent_id, created_at). Validate worktree created successfully (directory exists, git status clean). Log worktree creation for audit trail. Handle creation failures (insufficient disk space, git errors) with cleanup.

2. **Branch Management for Worktree Isolation:** Implement branch management isolating worktree work. Create worktree branch from current main branch (git branch <worktree-branch> main). Implement branch naming convention (feature/agent-<id>-<task-id>). Configure branch tracking remote (git branch --set-upstream-to=origin/main). Implement branch protection preventing accidental merges (require PR, no direct pushes). Track branch status (commits ahead/behind main, conflicts present). Support branch updates (git fetch, rebase on main if requested). Handle branch conflicts (detect conflicts, escalate to Manager). Cleanup merged branches (delete after successful merge). Maintain branch metadata in database (branch name, base commit, merge status).

3. **Agent-to-Worktree Mapping in Database:** Extend database schema (Task 1.1) tracking agent-worktree relationships. Add worktrees table: worktree_id, path, branch_name, agent_id (FK), created_at, merged_at, status (active/merged/abandoned). Add worktree_id column to agents table (FK to worktrees). Implement mapping functions: getWorktreeForAgent(agentId), getAgentForWorktree(worktreeId), listActiveWorktrees(). Update mapping on worktree lifecycle events (creation→map agent, merge→update status, cleanup→remove mapping). Query worktree status for monitoring (how many active, which agents in worktrees). Support multiple worktrees per agent (if agent reassigned). Validate mapping consistency (agent references valid worktree, no orphaned worktrees).

4. **Worktree Cleanup Procedures:** Implement cleanup for completed worktrees freeing disk space. Detect cleanup triggers: worktree branch merged to main (check merge status), agent terminated and worktree inactive (no pending work), manual cleanup request (apm-auto worktree clean). Execute cleanup procedure: verify worktree can be cleaned (all changes committed and pushed, branch merged or abandoned), remove worktree (git worktree remove <path> --force if needed), delete worktree branch (git branch -d <branch-name>), remove worktree directory (rm -rf <path>), update database marking worktree cleaned (status=merged/abandoned, cleaned_at=timestamp). Implement cleanup safeguards (confirm branch merged, warn if unmerged commits, require --force for destructive cleanup). Support cleanup dryrun showing what would be cleaned. Log all cleanup operations.

5. **Worktree Consistency Validation:** Implement validation ensuring worktree state consistent with git and database. Validate worktree exists on disk (directory at path, .git file present). Validate git worktree tracked (git worktree list shows worktree, branch exists). Validate database mapping current (worktree record exists, agent mapping valid). Check worktree status (git status clean vs dirty, commits ahead/behind main). Detect anomalies (worktree in database but not on disk, git worktree without database record, branch diverged significantly). Repair inconsistencies (remove stale database records, cleanup orphaned worktrees, recreate missing mappings). Generate consistency report listing issues and repairs. Run validation periodically (hourly background task) and on-demand (apm-auto worktree validate).

### Task 8.2 – Automated Merge Execution │ Agent_Git

- **Objective:** Implement automated merge execution system with merge strategy selection (fast-forward, three-way), execute merges with conflict detection, validate merge success, and update state database with merge results for coordination.
- **Output:** Merge execution module with strategy selection algorithm, automated merge logic, conflict detection, success validation, and database state updates.
- **Guidance:** Depends on Task 8.1 Output. Automate git merges when worktree work complete. Select merge strategy based on branch divergence (fast-forward if possible, three-way if needed). Execute merge (git merge). Detect conflicts during merge. Validate merge success (clean merge, tests pass). Update database with merge status. Follow TDD with mocked git operations for unit tests.

1. **Merge Strategy Selection:** Implement merge strategy selection algorithm choosing optimal strategy. Analyze branch divergence: check if worktree branch can fast-forward to main (git merge-base --is-ancestor), check if main can fast-forward to worktree branch (no divergence), detect diverged histories (both branches have unique commits). Select strategy: Fast-Forward (if main hasn't changed, simple fast-forward), Three-Way Merge (if both branches changed, merge commit needed), Rebase-Merge (rebase worktree on main then merge, linear history). Consider configuration preferences (prefer fast-forward for clean history, allow merge commits if needed). Validate strategy viable (no conflicts detected in analysis). Log strategy selection with rationale. Return selected strategy for execution.

2. **Automated Merge Execution:** Implement automated merge execution running git merge commands. Checkout target branch (git checkout main). Pull latest changes (git pull origin main ensuring up-to-date). Execute merge: Fast-forward (git merge --ff-only <worktree-branch>), Three-way merge (git merge --no-ff <worktree-branch> -m "Merge <worktree> into main"), Rebase merge (git rebase <worktree-branch> then git merge). Capture merge output parsing for conflicts or success. Handle merge in-progress state (conflicts detected, merge paused). Configure merge options (commit message template, merge strategy, conflict markers). Implement merge timeout (abort if merge hangs). Log all merge attempts with command, strategy, result. Support merge dryrun showing what would be merged without executing.

3. **Merge Conflict Detection and Success Validation:** Implement conflict detection during merge execution. Detect conflicts: parse git merge output for "CONFLICT" messages, check git status for unmerged paths, identify conflicting files list. Extract conflict details (file path, conflict type: content/rename/delete). Generate conflict report summarizing conflicts with file locations. For successful merges: validate merge commit created (git log shows merge commit), verify working directory clean (git status clean), validate no unmerged paths remaining. Run post-merge validation: execute tests (ensure tests still pass after merge), check build succeeds (TypeScript compiles), run linters (code style maintained). Mark merge successful only if all validations pass. Rollback merge if validation fails (git merge --abort, restore pre-merge state).

4. **Database State Updates:** Update database tracking merge status. Record merge attempt in merges table: merge_id, worktree_id, target_branch, strategy, started_at, completed_at, status (success/failed/conflicted), conflict_count, merge_commit_sha. Update worktree status (active→merged on success, active→conflicted on conflicts). Update task status (tasks assigned to worktree marked merged). Record merge metrics (duration, conflicts encountered, files changed). Implement atomic database updates (merge state changes in transaction). Emit merge events (merge_started, merge_completed, merge_failed, conflict_detected) for coordination. Query merge history (find all merges for worktree, get merge statistics). Generate merge reports (merge frequency, conflict rate, resolution time).

### Task 8.3 – Conflict Detection and Resolution │ Agent_Git

- **Objective:** Implement git conflict detection during merge operations, create AI agent delegation for conflict resolution analysis, add user feedback queue (immediate vs eventual) for conflict intervention, integrate resolution back into git workflow, and verify conflicts fully resolved.
- **Output:** Conflict detection system, AI agent delegation for resolution, user feedback queue with priority levels, resolution integration logic, and comprehensive conflict verification.
- **Guidance:** Depends on Task 8.2 Output. Detect conflicts during merge (Task 8.2). Delegate conflict analysis to AI merge resolution agent. Queue user feedback based on conflict complexity (immediate for complex conflicts, eventual for simple conflicts). Present conflict resolution options to user. Integrate user resolution back into git. Verify all conflicts resolved before completing merge. Follow TDD testing conflict scenarios.

1. **Conflict Detection During Merge:** Enhance conflict detection from Task 8.2 with detailed conflict analysis. Parse git conflict markers in files (<<<<<<< HEAD, =======, >>>>>>> branch). Classify conflict types: content conflicts (both sides modified same lines), rename conflicts (file renamed differently), delete conflicts (one side deleted, other modified), binary conflicts (binary files diverged). Analyze conflict complexity: simple (small diff, clear intent), moderate (larger changes, overlapping logic), complex (significant refactoring, incompatible changes). Extract conflict context (surrounding code, commit messages, authors). Generate conflict summary (total conflicts, breakdown by type and complexity, affected files). Prioritize conflicts (critical files first, simple conflicts last). Create conflict resolution tickets for delegation.

2. **AI Agent Delegation for Resolution:** Implement AI merge resolution agent delegation analyzing conflicts. Create Ad-Hoc agent specialized in merge conflict resolution (reference .claude/commands/apm-8-delegate-debug.md pattern). Provide conflict context to agent: conflicting files content, conflict markers, commit history, code context. Agent tasks: analyze both versions understanding intent, identify semantic differences vs formatting, recommend resolution strategy (accept ours, accept theirs, manual merge, refactor), generate resolution proposal. Return agent analysis with recommended resolution and confidence score. For high-confidence resolutions (>90%), suggest auto-apply. For low-confidence (<70%), escalate to user. Log all delegation and agent recommendations.

3. **User Feedback Queue (Immediate vs Eventual):** Implement user feedback queue handling conflict resolution requests per Context Synthesis requirement. Classify feedback urgency: Immediate (complex conflicts blocking progress, semantic conflicts requiring design decisions, high-risk changes like security code), Eventual (simple formatting conflicts, non-blocking changes, low-risk areas). Queue immediate feedback: pause automation, notify user immediately (console alert, notification), wait for user response before continuing. Queue eventual feedback: continue automation with other tasks, batch feedback requests (collect multiple conflicts), notify user periodically (every N conflicts or every hour), apply resolutions when user responds. Implement feedback UI (CLI prompts, web interface showing conflicts with diffs). Track feedback response time and user preferences adapting urgency classification.

4. **Resolution Integration into Git Workflow:** Implement conflict resolution integration applying user decisions to git. Parse user resolution choice: Accept Ours (git checkout --ours <file>), Accept Theirs (git checkout --theirs <file>), Manual Merge (user edits file removing conflict markers), Custom Resolution (apply user-provided diff/patch). Apply resolution to working directory. Stage resolved files (git add <file>). Validate resolution removed conflict markers (parse file, ensure no <<<<<<< remaining). Continue merge after all conflicts resolved (git merge --continue OR git commit completing merge). Run post-resolution validation (tests pass, build succeeds). Record resolution decision in database (file, resolution type, user/agent who resolved). Log resolution for audit and learning (improve future AI recommendations based on user choices).

5. **Conflict Resolution Verification:** Implement comprehensive verification ensuring conflicts fully resolved. Pre-completion checks: verify no conflict markers in any file (grep -r "<<<<<<" checking all files), check git status shows no unmerged paths, validate all conflicted files staged (git diff --cached). Run validation tests: compile code (TypeScript compiles without errors), execute test suite (all tests pass), run linters (no new linting errors introduced). Validate merge commit (commit message includes conflict resolution notes, all changes reviewed). Check for semantic conflicts (code compiles but logic broken, tests pass but behavior incorrect). Generate resolution report (conflicts resolved, methods used, validation results). Only mark merge complete if all verifications pass. Rollback and retry if verification fails.

### Task 8.4 – Conventional Commit Automation │ Agent_Git

- **Objective:** Implement conventional commit message generation from task context, enforce conventional commits format (feat/fix/chore/docs/etc), include metadata (task IDs, agent IDs) in commit messages, and validate commit message compliance with standards.
- **Output:** Commit message generator extracting context from tasks, format enforcement via pre-commit hook, metadata injection system, and compliance validator.
- **Guidance:** Generate conventional commit messages automatically from task completion context. Parse task type determining commit type (feature implementation→feat, bug fix→fix, refactor→refactor). Include task ID and agent ID in commit footer. Validate format via pre-commit hook (Task 5.2). Support manual override for custom messages. Follow TDD testing commit generation scenarios.

- **Commit Message Generation:** Implement commit message generator creating conventional commits from task context. Extract task information: task type (from Implementation Plan or beads), task description, scope (module/component affected), deliverables. Determine commit type: feat (new feature/functionality), fix (bug fix), refactor (code refactor), docs (documentation update), test (test addition), chore (maintenance), perf (performance improvement). Generate message structure: `<type>(<scope>): <subject>` (subject ≤50 chars, imperative mood, no period), optional body (detailed description, wrap at 72 chars), footer (Task-Id: X.Y, Agent-Id: agent-type, BREAKING CHANGE if applicable). Include metadata: link task ID for traceability, record agent for audit, note breaking changes. Validate generated message against conventional commits spec. Return formatted commit message ready for git commit.

- **Format Enforcement:** Integrate with pre-commit hook (Task 5.2) enforcing conventional commits format. Hook validates commit message before accepting commit. Check type valid (feat, fix, docs, etc. from allowed list). Validate scope format (optional, alphanumeric + hyphens, parentheses correct). Check subject (imperative mood, first word lowercase, ≤50 chars, no period). Validate body (blank line after subject, wrapped at 72 chars). Check footer format (Key: Value pairs, recognized keys). Reject commits with invalid format providing correction examples. Support override for exceptional cases (emergency commits) with justification. Log all enforcement events (accepts, rejects, overrides) for audit.

- **Metadata Injection System:** Implement metadata injection adding traceability to commits. Inject task ID footer: `Task-Id: 4.2` linking commit to Implementation Plan task. Add agent ID footer: `Agent-Id: Agent_Git` identifying which agent made commit. Include dependency references if relevant: `Depends-On: Task 8.1` for cross-task commits. Add breaking change notices: `BREAKING CHANGE: API endpoint changed` for incompatible changes. Support custom metadata: user-defined tags, issue references (#123), co-authors. Format metadata consistently (Footer-Key: Value on separate lines). Validate metadata values (task IDs exist in plan, agent IDs valid). Parse metadata from commits for reporting and analysis.

- **Compliance Validation:** Implement compliance validator checking commit history. Scan commit log parsing each commit message. Validate each commit against conventional format. Check compliance rate (percentage of commits following convention). Identify non-compliant commits (invalid type, wrong format, missing metadata). Generate compliance report (compliant/total, common violations, worst offenders). Implement compliance enforcement gates (block PR if compliance <95%, require fix commits). Support compliance correction (automated reformatting of commit messages, squash non-compliant commits). Track compliance trends (improving/degrading over time). Alert on compliance degradation.

## Phase 9: Terminal User Interface

### Task 9.1 – ink TUI Framework Setup │ Agent_TUI

- **Objective:** Configure ink TUI framework and dependencies enabling terminal-based user interface, create modular component structure for UI elements, implement state management for real-time UI updates, and add rendering pipeline with performance optimization.
- **Output:** ink framework configuration, component structure design, state management system, rendering pipeline, and performance optimization.
- **Guidance:** Setup ink (React-based TUI framework) for terminal interface. Create component architecture (tabs, status cards, logs, controls). Implement state management (use React hooks or Redux) for UI updates. Optimize rendering preventing flicker and excessive redraws. Follow React best practices adapted for terminal. Follow TDD testing UI components with ink-testing-library.

1. **ink Framework Configuration:** Setup ink framework and essential dependencies. Install ink and React (npm install ink react). Install ink components (ink-text-input, ink-select-input, ink-spinner, ink-table, ink-big-text). Configure TypeScript types (@types/react, ink type definitions). Setup render entry point (import {render} from 'ink', render(<App />)). Configure terminal environment (handle terminal resize, graceful exit on Ctrl+C, restore cursor on exit). Implement error boundary catching component errors. Setup development mode (hot reload for TUI development, debug logging). Configure production mode (minimize renders, optimize performance). Document ink patterns and conventions for team.

2. **Component Structure Design:** Design modular component architecture for TUI. Define component hierarchy: App (root) → Layout (tabs + content) → Tabs (navigation) + ContentArea (active tab content) → StatusDashboard | LogViewer | ControlPanel (tab-specific). Create reusable components: AgentCard (showing agent status), ProgressBar (task progress), LogLine (formatted log entry), CommandInput (user commands). Implement component props interfaces with TypeScript. Use composition over inheritance (small focused components). Separate presentation components (pure UI) from container components (state management). Export components from index for clean imports. Follow consistent naming conventions (PascalCase components, camelCase props).

3. **State Management Implementation:** Implement state management for UI updates. Use React hooks for local state (useState for simple state, useReducer for complex state). Implement global state with Context API (create AppContext providing shared state, useContext consuming state in components). Define state shape: AgentState (all active agents), TaskQueue (pending/in-progress tasks), LogBuffer (recent log entries), UIState (active tab, selected agent). Implement state update actions (updateAgentStatus, addLogEntry, selectTab). Connect state to data sources (subscribe to event bus from Task 3.4, poll database for updates, watch file changes). Optimize state updates (batch updates, prevent unnecessary renders, memoize expensive computations). Implement state persistence (save UI preferences, restore on restart).

4. **Rendering Pipeline Optimization:** Optimize ink rendering preventing flicker and performance issues. Implement render throttling (limit re-renders to 60fps, batch multiple updates). Use React.memo for expensive components (only re-render when props change). Implement shouldComponentUpdate logic (prevent renders when state unchanged). Optimize log rendering (virtual scrolling for large logs, render only visible lines). Minimize terminal writes (diff previous render, only output changes). Handle terminal resize efficiently (debounce resize events, reflow content). Implement progressive rendering (render critical UI first, defer non-critical). Profile rendering performance (measure render time, identify slow components). Test on various terminal emulators (iTerm, Terminal.app, Windows Terminal, tmux).

### Task 9.2 – Tabbed Agent Monitoring View │ Agent_TUI

- **Objective:** Implement tabbed navigation system for monitoring multiple agents simultaneously, create agent status cards displaying state and progress, add progress indicators for task execution, subscribe to state updates for real-time monitoring, and implement visual styling hierarchy.
- **Output:** Tab navigation component, agent status card components, progress visualization, state update subscription, and styled UI with visual hierarchy.
- **Guidance:** Depends on Task 9.1 Output and Task 2.3 Output by Agent_Orchestration_CLI and Task 4.2 Output by Agent_Orchestration_Automation. Create tabbed interface showing all active agents. Each tab displays agent status (active/waiting/idle), current task, progress, logs. Subscribe to agent state changes from Task 2.3 for real-time updates. Use colors and formatting for visual hierarchy (active=green, waiting=yellow, error=red). Follow TDD testing tab switching and status updates.

1. **Tab Navigation System:** Implement tab navigation component for multi-agent monitoring. Render tab bar with agent tabs (tab per active agent, tab label: Agent ID + status icon). Support tab selection (arrow keys or numbers 1-9 for quick select). Highlight active tab (inverse colors, bold text, arrow indicator). Display tab badges (task count, alerts, status). Implement tab scroll for many agents (>9 agents, scroll left/right). Support tab commands (n: next tab, p: previous tab, g: go to tab). Handle tab lifecycle (add tab when agent spawns, remove when agent terminates, update when agent state changes). Persist selected tab across renders. Use ink-tab or custom tab component.

2. **Agent Status Cards:** Create agent status card component displaying comprehensive agent information. Card layout: header (agent ID, type, status badge), body (current task ID and objective, progress bar with percentage, recent logs (last 5 lines), metrics: uptime, tasks completed, current memory usage), footer (last updated timestamp). Use colors for status: active (green), waiting (yellow), idle (cyan), blocked (red), terminated (gray). Render card for selected agent (large detailed card) or all agents (compact cards grid). Update cards in real-time (subscribe to agent state events). Implement card actions (click/enter to focus agent, 'k' to kill agent, 'r' to restart). Support card filtering (show only active, hide idle).

3. **Progress Indicators:** Implement progress visualization for task execution. Progress bar component: [=========>      ] 65% (filled characters for completed, empty for remaining). Update progress from task completion detection (Task 4.4) or agent progress reports. Show progress for: current task (sub-task completion %), phase progress (tasks completed/total), overall progress (all phases). Use spinners for indeterminate progress (agent working but no progress percentage available). Implement progress animations (smooth bar updates, spinner frames). Color-code progress: <30% red, 30-70% yellow, >70% green, 100% bright green. Display time estimates (estimated completion time based on current rate). Support progress comparison (multiple agents side-by-side).

4. **State Update Subscription:** Subscribe to state updates enabling real-time UI updates. Connect to event bus (Task 3.4) subscribing to agent/task events (agent:status_changed, task:progress, task:completed). Connect to lifecycle manager (Task 2.3) subscribing to state transitions. Poll database periodically (every 1s) for state changes (as fallback if events missed). Update UI state on event receipt triggering React re-render. Implement update throttling (max 10 updates/second preventing UI overload). Handle update errors gracefully (log error, skip update, continue monitoring). Support pause/resume updates (pause auto-updates, resume when user ready). Track update latency (time from state change to UI update).

5. **Visual Styling and Hierarchy:** Implement visual styling creating intuitive UI hierarchy. Use chalk for colors (status colors, syntax highlighting, emphasis). Apply text formatting (bold for headers, dim for metadata, underline for links). Implement visual hierarchy: primary info (large, bold, bright colors), secondary info (normal size, standard colors), tertiary info (small, dim colors). Use borders and boxes (box components separating sections). Implement responsive layout (adjust for terminal width, reflow content, hide non-critical info on small terminals). Create color themes (dark theme default, light theme optional, high-contrast mode for accessibility). Ensure readability (sufficient contrast, clear fonts, no color-only information for accessibility). Test visual design on various terminal sizes (80x24 minimum, 120x40 optimal).

### Task 9.3 – Real-time Log Display │ Agent_TUI

- **Objective:** Implement log streaming from agent processes displaying real-time output, create filtering logic for log levels and agent IDs, add log formatting with syntax highlighting, and implement scrolling and pagination for managing large log volumes.
- **Output:** Log streaming component, log filtering system, syntax highlighting formatter, scrolling and pagination controls, and comprehensive log display testing.
- **Guidance:** Depends on Task 9.1 Output. Stream logs from agent processes (stdout/stderr captured in Task 4.1) to TUI. Display logs with formatting (timestamps, log levels, agent IDs, colored output). Implement filtering (show only errors, filter by agent). Support scrolling (up/down arrows, page up/down). Paginate large logs. Follow TDD testing log display and filtering.

1. **Log Streaming Implementation:** Implement log streaming displaying agent output in real-time. Subscribe to agent process output streams (from Task 4.1 process monitoring). Buffer log lines (max 10000 lines, drop oldest when full). Parse log format extracting: timestamp, log level (ERROR, WARN, INFO, DEBUG), agent ID, message. Render log lines in reverse chronological order (newest first). Implement auto-scroll (scroll to newest log by default, lock scroll when user scrolls up). Stream logs with minimal latency (<100ms from log generation to display). Handle high-volume logs (throttle display to 100 lines/second, batch updates). Support log pause/resume (pause streaming, resume when ready).

2. **Log Filtering Logic:** Implement log filtering reducing noise. Filter by log level (show only ERROR+WARN, hide DEBUG). Filter by agent ID (show logs from selected agent only). Filter by keyword (search log messages, highlight matches). Combine filters (AND logic: level=ERROR AND agent=Agent_Git). Implement filter UI (filter input box, quick filter buttons). Apply filters in real-time (re-filter on criteria change, update display immediately). Display filter status (show active filters, total logs vs filtered logs). Persist filter preferences (save filter settings, restore on restart). Support filter presets (common filter combinations, one-click activation).

3. **Log Formatting with Syntax Highlighting:** Implement log formatting improving readability. Format timestamps (relative: "2m ago", absolute: "14:32:15"). Color log levels (ERROR: red, WARN: yellow, INFO: white, DEBUG: dim). Syntax highlight messages (stack traces: highlight file paths, JSON logs: colorize keys/values, URLs: blue and underline). Truncate long lines (wrap at terminal width OR truncate with ellipsis). Format special logs (task completion: green with checkmark, blockers: red with X, handover: yellow with arrow). Use chalk for colors, apply ANSI codes. Implement copy-to-clipboard (select log line, copy to system clipboard). Support log export (save filtered logs to file).

4. **Scrolling and Pagination:** Implement scrolling for log navigation. Scroll controls: Up/Down arrows (scroll one line), Page Up/Down (scroll one page), Home/End (jump to top/bottom), Mouse wheel (scroll if supported). Display scroll indicator (position in log buffer, "Line 50/1000"). Implement smooth scrolling (debounce rapid scroll events). Lock scroll position (when user scrolls, disable auto-scroll to newest). Resume auto-scroll (when user scrolls to bottom, re-enable auto-scroll). Implement search navigation (n: next match, p: previous match after keyword search). Show scroll hints ("More logs above ↑", "Scroll to bottom ↓"). Handle wrap-around (optional: scroll past top wraps to bottom).


### Task 9.4 – User Interaction Controls │ Agent_TUI

- **Objective:** Implement keyboard shortcuts for TUI navigation and agent control, add command input for executing apm-auto commands within TUI, support interactive approval prompts for user feedback queue, and integrate with communication protocol for sending commands to agents.
- **Output:** Keyboard shortcut system, command input component, interactive approval interface, command routing to agents, and comprehensive interaction testing.
- **Guidance:** Depends on Task 9.1 Output and Task 3.3 Output by Agent_Communication. Add keyboard controls for TUI navigation (tab switching, scrolling, filtering). Implement command input for executing apm-auto commands without leaving TUI. Support interactive approval for user feedback queue (Task 8.3) displaying approval prompts in TUI. Route commands to agents via communication protocol. Follow TDD testing user interactions.

1. **Keyboard Shortcut System:** Implement keyboard controls for TUI navigation. Define global shortcuts: Tab/Shift+Tab (switch tabs), 1-9 (quick tab select), q (quit TUI), h (help overlay), / (search/filter), r (refresh). Define context shortcuts (active when specific view focused): Logs view (↑↓ scroll, PgUp/PgDn page, / search, f filter menu), Agent view (k kill agent, p pause, r resume, d details), Command input (Ctrl+C cancel, Enter submit, ↑↓ command history). Capture keypress events (use ink's useInput hook). Map keys to actions (switch statement or action registry). Handle key conflicts (context-specific bindings override global). Display shortcut hints (footer bar showing available shortcuts, help overlay with all shortcuts). Support customizable shortcuts (user config for keybindings).

2. **Command Input Component:** Implement command input enabling apm-auto commands within TUI. Render command input box (bottom of screen, `:` prompt like vim, text input field). Capture user input (ink-text-input component, handle Enter to submit, Esc to cancel). Parse command (apm-auto commands: start, pause, resume, kill, status, worktree, config). Execute command (route to CLI command handlers from Task 2.1, display result in TUI). Support command history (↑↓ navigate previous commands, store in memory or file). Implement command autocomplete (Tab completes command names, suggest agent IDs). Display command output (success messages, error messages, command results). Support command shortcuts (: for command mode, @ for agent-specific commands).

3. **Interactive Approval Prompts:** Implement approval prompts for user feedback queue (from Task 8.3). Display approval request (modal overlay OR dedicated approval pane, show context: conflict details, proposed resolution, options: Approve/Reject/Edit). Render approval options (y: approve, n: reject, e: edit, s: skip for now). Capture user selection (keyboard shortcuts, highlight selected option, Enter confirms). Return approval decision (route to conflict resolution system Task 8.3, update agent state based on decision). Support approval queue (show pending approvals count, navigate between approvals, batch approve/reject). Implement approval timeout (auto-escalate if user doesn't respond in N minutes). Log all approval decisions for audit.

4. **Command Routing to Agents:** Route TUI commands to agents via communication protocol. Use event bus (Task 3.4) emitting command events (command:agent_pause, command:agent_kill, command:user_approval). Target specific agents (route command to agent by ID, broadcast commands if no target). Wait for agent response (agents emit response events via protocol, display response in TUI, timeout if no response). Implement command acknowledgment (agents confirm command receipt, TUI shows "command sent" → "acknowledged" → "completed"). Support command cancellation (cancel in-flight commands, send cancel event to agent). Handle command errors (agent rejects command, display error in TUI, suggest alternatives). Log all command routing for debugging.

## Phase 10: Enhanced Autonomy (v3)

### Task 10.1 – Autonomy Level Framework │ Agent_Orchestration_Autonomy

- **Objective:** Design and implement autonomy level system enabling configurable automation modes (Cautious, Automated, YOLO), define decision-making thresholds and gating rules for each level, create autonomy level configuration storage and retrieval, and implement level transitions during runtime.
- **Output:** Autonomy level enumeration and configuration schema, decision threshold matrix, configuration persistence, runtime level transition logic, and comprehensive level testing.
- **Guidance:** Implement three autonomy levels per Context Synthesis requirement. Cautious: require approval for risky operations (git pushes, destructive commands, external API calls). Automated: auto-approve most operations, require approval only for critical decisions (production deploys, breaking changes). YOLO: full automation, no approvals except catastrophic failures. Store level in config. Support runtime level changes. Follow TDD testing level behaviors.

1. **Autonomy Level Definition:** Define autonomy levels as TypeScript enum with configuration. Create AutonomyLevel enum: CAUTIOUS (conservative automation, require approvals), AUTOMATED (balanced automation, minimal approvals), YOLO (maximum automation, trust AI fully). Define level characteristics: approval_threshold (what requires approval at this level), auto_retry (retry failed operations automatically), risk_tolerance (acceptable risk level for auto-approval), user_interaction_frequency (how often to request user input). Create level configuration schema: JSON structure defining thresholds, TypeScript interface for type safety, validation ensuring valid configurations. Document level behaviors (README explaining when to use each level, examples of operations at each level). Implement level presets (default configurations for each level, customizable by user).

2. **Decision Threshold Matrix:** Implement decision threshold matrix mapping operations to approval requirements. Define operation categories: git_operations (commit, push, merge, branch delete), external_api_calls (network requests, third-party APIs), destructive_operations (file delete, database drop, branch force-push), breaking_changes (API changes, schema migrations), deployment_operations (production deploy, rollback). Create threshold matrix: CAUTIOUS (git push→approval required, API calls→approval required, destructive→approval required, breaking→approval required, deploy→approval required), AUTOMATED (git push→auto-approve, API calls→approval if external, destructive→approval required, breaking→approval required, deploy→approval if production), YOLO (all→auto-approve except catastrophic failures). Implement threshold lookup (given operation and autonomy level, return approval required boolean). Support custom thresholds (user overrides default matrix, persist overrides in config).

3. **Configuration Storage and Retrieval:** Implement configuration persistence for autonomy settings. Store config in SQLite database (config table: key, value, updated_at). Store autonomy level (current_autonomy_level: "CAUTIOUS"|"AUTOMATED"|"YOLO"). Store custom thresholds (operation_thresholds: JSON blob with overrides). Implement config getter (getCurrentAutonomyLevel(), getOperationThreshold(operation)). Implement config setter (setAutonomyLevel(level), setOperationThreshold(operation, threshold)). Validate config values (level is valid enum, thresholds match schema). Provide config defaults (AUTOMATED default level, standard thresholds). Emit config change events (config:autonomy_level_changed for subscribers). Support config export/import (backup config, share across projects).

4. **Runtime Level Transitions:** Implement runtime autonomy level changes without restart. Add command (apm-auto config autonomy <level> changing level on-the-fly). Validate transition (confirm new level valid, warn user of behavior changes). Apply transition (update database config, emit level change event, notify all agents of new level). Handle in-flight operations (operations started under old level continue with old rules, new operations use new level). Implement level transition hooks (on transition to CAUTIOUS: warn about approvals, on transition to YOLO: confirm user understands risks). Support temporary level changes (--autonomy-level flag for single command, revert to config default after). Log all level changes (timestamp, old level, new level, user who changed).

### Task 10.2 – Approval Workflow Engine │ Agent_Orchestration_Autonomy

- **Objective:** Implement approval request generation based on autonomy level and operation risk, create approval queue management with prioritization, add approval decision execution applying user choices, and integrate with user feedback queue from Task 8.3 for unified approval interface.
- **Output:** Approval request generator, approval queue manager, decision executor, unified feedback queue integration, and approval workflow testing.
- **Guidance:** Depends on Task 10.1 Output and Task 8.3 Output by Agent_Git. Generate approval requests when operation exceeds autonomy threshold. Queue approvals (immediate vs eventual per Task 8.3). Present approval UI (CLI prompts, TUI interface from Task 9.4). Execute user decision (approve→proceed, reject→skip, edit→modify then proceed). Integrate with conflict resolution feedback queue for unified user experience. Follow TDD testing approval workflows.

1. **Approval Request Generation:** Implement approval request generator creating requests when threshold exceeded. Detect approval trigger (before executing operation, check autonomy level and operation type, lookup threshold from Task 10.1, if approval required→generate request). Create approval request object: operation_id, operation_type, description (human-readable operation summary), risk_level (low/medium/high/critical), context (operation details, affected resources, potential impact), default_action (suggested approval decision based on AI analysis), autonomy_level (level at request time). Enrich request with context (relevant code changes, affected files, task objective). Estimate operation impact (files changed, potential errors, rollback difficulty). Generate request ID (unique ID for tracking).

2. **Approval Queue Management:** Implement approval queue prioritizing and batching requests. Maintain approval queue in database (approval_requests table: request_id, operation_id, priority, status, created_at, resolved_at). Prioritize requests: critical (blocking progress, high risk)→top priority, high (important but not blocking)→high priority, medium (can be batched)→medium priority, low (cosmetic, non-blocking)→low priority. Implement queue operations: enqueue(request) adding to queue, dequeue() retrieving highest priority request, peek() viewing next request without removing, count() getting queue size. Support queue filtering (show only critical, filter by operation type). Emit queue events (request_queued, queue_length_changed). Implement queue timeout (auto-reject requests older than threshold, escalate stale requests).

3. **Approval Decision Execution:** Implement decision executor applying user approval choices. Capture user decision (approve, reject, edit, defer). Validate decision (ensure valid choice, confirm operation still valid). Execute based on decision: Approve (proceed with operation, mark request resolved, log approval), Reject (cancel operation, mark request rejected, log rejection, notify agent operation cancelled), Edit (present operation for modification, apply user changes, re-queue for approval), Defer (postpone decision, re-queue with lower priority). Update operation state (approved operations→proceed to execution, rejected→mark cancelled). Record decision in database (approval_id, user_decision, decision_timestamp, justification if provided). Emit decision events (approval:approved, approval:rejected for coordination).

4. **Unified Feedback Queue Integration:** Integrate approval workflow with conflict resolution feedback queue (Task 8.3) for unified experience. Merge approval and conflict queues (single user feedback queue, requests tagged by type: approval/conflict). Implement unified queue interface (consistent API for both approval and conflict feedback, common prioritization logic). Present unified UI (Task 9.4 TUI shows all pending feedback, CLI prompts handle both types). Route feedback to appropriate handlers (approval requests→approval executor, conflict requests→conflict resolver). Maintain separate tracking (approvals in approval_requests table, conflicts in merge_conflicts table, unified view joins both). Support batch operations (approve all low-risk, resolve all simple conflicts). Emit unified events (user_feedback_requested, user_feedback_resolved).

### Task 10.3 – Decision-Making Logic │ Agent_Orchestration_Autonomy

- **Objective:** Implement AI-driven decision-making suggesting optimal actions, create risk assessment scoring operations by potential impact, add auto-approval logic for low-risk decisions within autonomy bounds, and integrate decision logging for audit trail and learning feedback loop.
- **Output:** AI decision engine, risk assessment module, auto-approval system, decision audit log, and comprehensive decision testing.
- **Guidance:** Depends on Task 10.1 Output. Implement AI decision-making suggesting actions for approval requests. Assess operation risk scoring 0-100 (low-risk→auto-approve in AUTOMATED/YOLO, high-risk→always require approval). Auto-approve low-risk operations within autonomy level bounds. Log all decisions (auto-approved, user-approved, rejected) for audit and ML training. Follow TDD testing decision scenarios.

1. **AI Decision Engine:** Implement AI decision engine analyzing operations and suggesting actions. Analyze operation context (task objective, code changes, test results, similar past operations). Generate recommendation: action (approve/reject/needs-review), confidence (0-100% how confident AI is in recommendation), rationale (why AI suggests this action), alternatives (other possible actions). Use heuristics: operations matching successful patterns→approve, operations with test failures→reject, operations with unknown patterns→needs-review. Consider historical data (similar operations that succeeded→approve, operations that previously failed→reject, user override patterns→adjust confidence). Return recommendation to approval workflow (suggestion displayed in approval UI, auto-approve if confidence >90% and autonomy level allows). Implement recommendation feedback loop (track recommendation accuracy, learn from user overrides, improve future recommendations).

2. **Risk Assessment Module:** Implement risk assessment scoring operations 0-100. Define risk factors: scope (files changed, lines of code, modules affected), test_coverage (how much code covered by tests), reversibility (can operation be easily undone), external_dependencies (calls to external APIs, network operations), data_criticality (affects user data, production database), deployment_target (dev/staging/production). Calculate risk score: sum weighted factors (scope×0.2 + test_coverage×0.3 + reversibility×0.1 + external_deps×0.2 + data_crit×0.15 + deploy_target×0.05), normalize to 0-100 range, classify: 0-30 low, 31-60 medium, 61-85 high, 86-100 critical. Return risk assessment object (score, classification, breakdown by factor, mitigation suggestions). Use risk score in approval decision (low risk→auto-approve in AUTOMATED, high risk→require approval even in YOLO).

3. **Auto-Approval Logic:** Implement auto-approval system for low-risk operations within autonomy bounds. Check auto-approval eligibility (lookup autonomy level, get risk score, check operation type against threshold matrix). Evaluate auto-approval conditions: risk_score ≤ threshold for autonomy level, AI confidence ≥ minimum (e.g., 80%), no user-defined block on operation type, no recent failures of similar operations. Auto-approve if eligible (skip approval queue, execute operation immediately, log auto-approval decision). Require approval otherwise (enqueue approval request, notify user, wait for decision). Implement auto-approval safeguards (max N auto-approvals per hour to prevent runaway automation, circuit breaker: disable auto-approval after M consecutive failures). Emit auto-approval events (operation:auto_approved for monitoring).

4. **Decision Audit Log:** Implement comprehensive decision logging for audit and learning. Log all decisions to database (decisions table: decision_id, operation_id, decision_type: auto-approved/user-approved/rejected, risk_score, ai_confidence, ai_recommendation, user_override: boolean, decision_timestamp, outcome: success/failure/unknown). Record decision context (autonomy level at decision time, threshold applied, risk factors breakdown). Track decision outcomes (operation completed successfully→outcome=success, operation failed→outcome=failure, update decision record post-execution). Generate decision reports (approval rate by autonomy level, override frequency, risk score accuracy). Implement learning feedback loop (analyze user overrides identifying patterns AI missed, adjust risk weights if systematic errors, improve AI recommendations based on historical accuracy). Support decision export (CSV/JSON for external analysis).

### Task 10.4 – User Preference Management │ Agent_Orchestration_Autonomy

- **Objective:** Implement user preference storage for customizing autonomy behavior, create preference discovery learning from user approval patterns, add preference UI for configuring automation settings, and integrate preferences with autonomy level and threshold matrix.
- **Output:** Preference storage schema, preference learning algorithm, preference configuration UI, preference integration with autonomy system, and preference management testing.
- **Guidance:** Depends on Task 10.1 Output and Task 10.2 Output. Store user preferences (preferred autonomy level, custom operation thresholds, notification preferences). Learn preferences from user behavior (user always approves X→auto-approve X in future, user always rejects Y→block Y). Provide UI for preference management (apm-auto config preferences, TUI settings panel). Integrate preferences with autonomy framework overriding defaults. Follow TDD testing preference application.

1. **Preference Storage Schema:** Implement user preference storage in database. Create user_preferences table: preference_id, preference_key (e.g., "autonomy.level", "threshold.git_push"), preference_value (JSON value), preference_source (user-set/learned), confidence (0-100 if learned), created_at, updated_at. Define preference categories: autonomy (autonomy level, risk tolerance), thresholds (custom operation thresholds overriding defaults), notifications (notification frequency, channels), workflow (auto-retry enabled, approval timeout), ui (TUI theme, log verbosity). Implement preference API: getPreference(key, default), setPreference(key, value, source), deletePreference(key), listPreferences(category). Validate preference values (type-check, range-check). Support preference hierarchy (project-specific preferences override global defaults).

2. **Preference Learning Algorithm:** Implement preference learning discovering patterns from user behavior. Track user decisions (record every approval/rejection/edit in decision log from Task 10.3). Analyze decision patterns: for each operation type, calculate approval rate (approved/total decisions), identify consistent patterns (user always approves operation X: approval rate >90% over 10+ decisions, user always rejects operation Y: rejection rate >90%), detect preference changes (pattern shifts over time). Generate learned preferences: if consistent approval pattern→create preference auto-approving operation, if consistent rejection pattern→create preference blocking operation, set confidence based on pattern strength (90% approval→90% confidence). Propose learned preferences to user (notify: "You've approved git push 15 times, auto-approve in future?", user confirms→persist preference). Implement preference drift detection (if user starts rejecting previously approved operation→lower confidence, suggest removing learned preference).

3. **Preference Configuration UI:** Implement preference management UI in CLI and TUI. CLI commands: `apm-auto config preferences list` (show all preferences with values and sources), `apm-auto config preferences set <key> <value>` (set preference), `apm-auto config preferences unset <key>` (remove preference), `apm-auto config preferences reset` (reset to defaults). TUI settings panel (from Task 9.4): tabbed settings view (Autonomy, Thresholds, Notifications, Workflow tabs), interactive controls (select dropdowns for enums, sliders for numeric values, toggles for booleans), live preview (show how preference affects behavior), save/cancel buttons. Display preference metadata (show if user-set or learned, show confidence for learned, show last updated timestamp). Implement preference export/import (backup preferences to JSON file, restore from file).

4. **Preference Integration:** Integrate preferences with autonomy system overriding defaults. Load preferences at startup (read from database, cache in memory for fast access). Apply preferences to autonomy framework: override autonomy level if user preference set, override threshold matrix with custom thresholds, apply workflow preferences (auto-retry, timeouts). Check preferences before decisions: get operation threshold from preferences first, fall back to default matrix if no preference, apply user preference overriding AI recommendation if set. Emit preference events (preference:changed, preference:applied for monitoring). Support preference scoping (global preferences for all projects, project-specific preferences for current project, session preferences for current run only). Implement preference validation (ensure preferences don't conflict, warn if risky preference combinations like "YOLO + no approvals").

---

**End of Implementation Plan**

*This plan provides detailed guidance for all 40 tasks across 10 phases. Manager Agent should proceed with agent assignments and coordination following the 11-step workflow defined in the APM Manager Agent Guide.*
